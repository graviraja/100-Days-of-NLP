{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER tagging with Char-BiLSTM-CRF.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2haF4Hn2kRNz",
        "vIFVl-O_kUJb",
        "RBVQHwTVk88N",
        "wwiiGscn29-V",
        "1Fpc9vWq3EY3",
        "zv1kwAoG3IzE",
        "TeoX6uxx3MVe",
        "5urAtI4W3OUf",
        "TIXBCe7S3c3y"
      ],
      "authorship_tag": "ABX9TyMKmQCgsgyfybE+fn/Qp2Ub",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fclassification/NER%20tagging%20with%20Char-BiLSTM-CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeK9dZJmkDQg",
        "colab_type": "text"
      },
      "source": [
        "### NER Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5jkJpQvdgjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "bcc697fe-0fca-44c4-c830-09d9ad6cc3a6"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5eEi8pCZYYu",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fd7934a6-5d8d-499d-ec74-244a366eaa86"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-179c3d3f-768f-48df-b2ad-0da9fa9b49ca\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-179c3d3f-768f-48df-b2ad-0da9fa9b49ca\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ravirajag\",\"key\":\"7c9b32c3baf1bd5e404db6e4e281fc5c\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBOvFvrBdm1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKDfern7eAi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6d9d2206-27c8-4389-c7b8-003f344f1697"
      },
      "source": [
        "!kaggle datasets download -d abhinavwalia95/entity-annotated-corpus"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading entity-annotated-corpus.zip to /content\n",
            " 64% 17.0M/26.4M [00:00<00:00, 25.6MB/s]\n",
            "100% 26.4M/26.4M [00:00<00:00, 41.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1LvqrEIeFvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "183cd3a3-3f01-400c-b4ad-3c77f896afc4"
      },
      "source": [
        "!unzip entity-annotated-corpus.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  entity-annotated-corpus.zip\n",
            "  inflating: ner.csv                 \n",
            "  inflating: ner_dataset.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuSoeUl3kFz2",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD_gnl5YQHEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NemuvQdVpGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "227fefaa-65f0-4e19-c66d-46aa8fa2c778"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNeeukPGkLSC",
        "colab_type": "text"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM1ADdqCeRcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datafile = 'ner_dataset.csv'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXIfU9fBfB6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(datafile, encoding=\"latin1\", error_bad_lines=False)\n",
        "df = df.fillna(method='ffill')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T1WOTYVfRLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "9095d23f-73fc-4ad9-fcc4-a960f9ad556a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAzzVjPqf7Lb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d21ab03-9cb8-4c65-ba09-31a44216f4af"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1048575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c16vzijfkwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "f13b49ce-53a5-431e-c281-340bda9f5ec6"
      },
      "source": [
        "tags = list(df.Tag.unique())\n",
        "tags"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-geo',\n",
              " 'B-gpe',\n",
              " 'B-per',\n",
              " 'I-geo',\n",
              " 'B-org',\n",
              " 'I-org',\n",
              " 'B-tim',\n",
              " 'B-art',\n",
              " 'I-art',\n",
              " 'I-per',\n",
              " 'I-gpe',\n",
              " 'I-tim',\n",
              " 'B-nat',\n",
              " 'B-eve',\n",
              " 'I-eve',\n",
              " 'I-nat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eKeAR8DftPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "d68b5a2a-f6a3-4662-cbe6-b7b74d0ef236"
      },
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "sns.countplot(df.Tag.values)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f20f3592048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPDMLtKdhFrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1eadc6d9-44d0-47ea-dae9-7c9b6bbf682d"
      },
      "source": [
        "num_tags = len(tags)\n",
        "num_tags"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2haF4Hn2kRNz",
        "colab_type": "text"
      },
      "source": [
        "### Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSmI25jJhjLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agg_func = lambda s: [(w, t) for w, p, t in zip(s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist())]\n",
        "group = df.groupby(\"Sentence #\").apply(agg_func)\n",
        "lines = [s for s in group]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RknB-LoUiATn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "8d21c2d1-7f7d-4da0-a709-8822e93c797b"
      },
      "source": [
        "lines[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Thousands', 'O'),\n",
              " ('of', 'O'),\n",
              " ('demonstrators', 'O'),\n",
              " ('have', 'O'),\n",
              " ('marched', 'O'),\n",
              " ('through', 'O'),\n",
              " ('London', 'B-geo'),\n",
              " ('to', 'O'),\n",
              " ('protest', 'O'),\n",
              " ('the', 'O'),\n",
              " ('war', 'O'),\n",
              " ('in', 'O'),\n",
              " ('Iraq', 'B-geo'),\n",
              " ('and', 'O'),\n",
              " ('demand', 'O'),\n",
              " ('the', 'O'),\n",
              " ('withdrawal', 'O'),\n",
              " ('of', 'O'),\n",
              " ('British', 'B-gpe'),\n",
              " ('troops', 'O'),\n",
              " ('from', 'O'),\n",
              " ('that', 'O'),\n",
              " ('country', 'O'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLJvFI3yqgi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [['<START>'] + [tokens[0] for tokens in line] + ['<END>'] for line in lines]\n",
        "tags = [['<START>'] + [tokens[1] for tokens in line] + ['<END>'] for line in lines]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Q6hAx4SU22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = [[['<START']] + [['<START>'] + [ch for ch in word] + ['<END>'] for word in sent[1:-1]] + [['<END>']] for sent in sentences]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A0xItc3iFhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1336bc8f-1040-4ac3-846a-1728b7a7cb09"
      },
      "source": [
        "len(sentences), len(tags), len(chars)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47959, 47959, 47959)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u29TiWBiSQuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "b787f0cf-4f6b-4a45-916a-421c9b9ea05e"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<START>',\n",
              " 'Thousands',\n",
              " 'of',\n",
              " 'demonstrators',\n",
              " 'have',\n",
              " 'marched',\n",
              " 'through',\n",
              " 'London',\n",
              " 'to',\n",
              " 'protest',\n",
              " 'the',\n",
              " 'war',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'and',\n",
              " 'demand',\n",
              " 'the',\n",
              " 'withdrawal',\n",
              " 'of',\n",
              " 'British',\n",
              " 'troops',\n",
              " 'from',\n",
              " 'that',\n",
              " 'country',\n",
              " '.',\n",
              " '<END>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1jcQSbGStyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "46b0becf-2ac2-48db-e5ce-33528699aa6b"
      },
      "source": [
        "chars[0]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<START'],\n",
              " ['<START>', 'T', 'h', 'o', 'u', 's', 'a', 'n', 'd', 's', '<END>'],\n",
              " ['<START>', 'o', 'f', '<END>'],\n",
              " ['<START>',\n",
              "  'd',\n",
              "  'e',\n",
              "  'm',\n",
              "  'o',\n",
              "  'n',\n",
              "  's',\n",
              "  't',\n",
              "  'r',\n",
              "  'a',\n",
              "  't',\n",
              "  'o',\n",
              "  'r',\n",
              "  's',\n",
              "  '<END>'],\n",
              " ['<START>', 'h', 'a', 'v', 'e', '<END>'],\n",
              " ['<START>', 'm', 'a', 'r', 'c', 'h', 'e', 'd', '<END>'],\n",
              " ['<START>', 't', 'h', 'r', 'o', 'u', 'g', 'h', '<END>'],\n",
              " ['<START>', 'L', 'o', 'n', 'd', 'o', 'n', '<END>'],\n",
              " ['<START>', 't', 'o', '<END>'],\n",
              " ['<START>', 'p', 'r', 'o', 't', 'e', 's', 't', '<END>'],\n",
              " ['<START>', 't', 'h', 'e', '<END>'],\n",
              " ['<START>', 'w', 'a', 'r', '<END>'],\n",
              " ['<START>', 'i', 'n', '<END>'],\n",
              " ['<START>', 'I', 'r', 'a', 'q', '<END>'],\n",
              " ['<START>', 'a', 'n', 'd', '<END>'],\n",
              " ['<START>', 'd', 'e', 'm', 'a', 'n', 'd', '<END>'],\n",
              " ['<START>', 't', 'h', 'e', '<END>'],\n",
              " ['<START>', 'w', 'i', 't', 'h', 'd', 'r', 'a', 'w', 'a', 'l', '<END>'],\n",
              " ['<START>', 'o', 'f', '<END>'],\n",
              " ['<START>', 'B', 'r', 'i', 't', 'i', 's', 'h', '<END>'],\n",
              " ['<START>', 't', 'r', 'o', 'o', 'p', 's', '<END>'],\n",
              " ['<START>', 'f', 'r', 'o', 'm', '<END>'],\n",
              " ['<START>', 't', 'h', 'a', 't', '<END>'],\n",
              " ['<START>', 'c', 'o', 'u', 'n', 't', 'r', 'y', '<END>'],\n",
              " ['<START>', '.', '<END>'],\n",
              " ['<END>']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH_xnhJFkj1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "aa7a888d-ff5f-49a5-9478-2f90cdb36274"
      },
      "source": [
        "sen_lengths = [len(sent) for sent in sentences]\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.countplot(sen_lengths)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f20dfc60550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4b87TebTsen",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "52e2f376-ce68-40e1-8568-bd93984ebd60"
      },
      "source": [
        "char_lengths = [len(t) for char in chars for t in char]\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.countplot(char_lengths)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f20f227ac50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5HlzOzGmEDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2685ff2c-05ec-4b39-e806-58bcfa2d4165"
      },
      "source": [
        "train_sentences, valid_sentences, train_tags, valid_tags, train_chars, valid_chars = train_test_split(sentences, tags, chars, test_size=0.2, random_state=42)\n",
        "valid_sentences, test_sentences, valid_tags, test_tags, valid_chars, test_chars = train_test_split(valid_sentences, valid_tags, valid_chars, test_size=0.5, random_state=42)\n",
        "len(train_sentences), len(valid_sentences), len(test_sentences)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38367, 4796, 4796)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFVl-O_kUJb",
        "colab_type": "text"
      },
      "source": [
        "### Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9eJdmdhoamw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocab:\n",
        "    def __init__(self, word2id, id2word):\n",
        "        self.UNK = '<UNK>'\n",
        "        self.PAD = '<PAD>'\n",
        "        self.START = '<START>'\n",
        "        self.END = '<END>'\n",
        "        self.__word2id = word2id\n",
        "        self.__id2word = id2word\n",
        "\n",
        "    def get_word2id(self):\n",
        "        return self.__word2id\n",
        "\n",
        "    def get_id2word(self):\n",
        "        return self.__id2word\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        if self.UNK in self.__word2id:\n",
        "            return self.__word2id.get(item, self.__word2id[self.UNK])\n",
        "        return self.__word2id[item]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.__word2id)\n",
        "\n",
        "    def id2word(self, idx):\n",
        "        return self.__id2word[idx]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YlwfEdHocqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(data, freq_cutoff=5, is_tags=False, is_chars=False):\n",
        "    if is_chars:\n",
        "        word_counts = Counter(chain(*chain(*train_chars[:10])))\n",
        "    else:\n",
        "        word_counts = Counter(chain(*data))\n",
        "    valid_words = [w for w, d in word_counts.items() if d >= freq_cutoff]\n",
        "    valid_words = sorted(valid_words, key=lambda x: word_counts[x], reverse=True)\n",
        "    valid_words += ['<PAD>']\n",
        "    word2id = {w: idx for idx, w in enumerate(valid_words)}\n",
        "    if not is_tags:\n",
        "        word2id['<UNK>'] = len(word2id)\n",
        "        valid_words += ['<UNK>']\n",
        "    return Vocab(word2id=word2id, id2word=valid_words)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzicTNXdj8Rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_vocab = build_vocab(train_sentences)\n",
        "tags_vocab = build_vocab(train_tags, is_tags=True)\n",
        "chars_vocab = build_vocab(train_chars, is_chars=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2LrPT8HUvHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7be4a1aa-45d7-440d-e275-3854a3483a3f"
      },
      "source": [
        "len(words_vocab), len(tags_vocab), len(chars_vocab)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9620, 20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBVQHwTVk88N",
        "colab_type": "text"
      },
      "source": [
        "### NER Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3RhXjbdk_Jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LEN = 50\n",
        "MAX_WORD_LEN = 15"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToE09rDqx8Bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NERDataset(data.Dataset):\n",
        "    def __init__(self, sentences, tags, chars, max_seq_len, max_word_len):\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.characters = chars\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.max_word_len = max_word_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        sentence = self.sentences[item]\n",
        "        tag = self.tags[item]\n",
        "        chars = self.characters[item]\n",
        "        seq_len = len(sentence)\n",
        "\n",
        "        # convert the sentences and tags into numerical format\n",
        "        word_tokens = [words_vocab[word] for word in sentence]\n",
        "        tag_tokens = [tags_vocab[t] for t in tag]\n",
        "\n",
        "        char_seq = []\n",
        "        for word in chars:\n",
        "            word_len = len(word)\n",
        "            # truncate the word if it is greater than max_word_len\n",
        "            if word_len > self.max_word_len:\n",
        "                word = word[:self.max_word_len]\n",
        "            # pad the word if it less\n",
        "            else:\n",
        "                pad_length = self.max_word_len - word_len\n",
        "                word = word + [chars_vocab.PAD] * pad_length\n",
        "            \n",
        "            # convert the chars into numerical format\n",
        "            char_ids = []\n",
        "            for each_char in word: \n",
        "                char_ids.append(chars_vocab[each_char])\n",
        "            char_seq.append(char_ids)\n",
        "        \n",
        "        return torch.LongTensor(word_tokens), torch.LongTensor(char_seq), torch.LongTensor(tag_tokens)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPJmCn-VyQDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = NERDataset(train_sentences, train_tags, train_chars, MAX_SEQ_LEN, MAX_WORD_LEN)\n",
        "valid_dataset = NERDataset(valid_sentences, valid_tags, valid_chars, MAX_SEQ_LEN, MAX_WORD_LEN)\n",
        "test_dataset = NERDataset(test_sentences, test_tags, test_chars, MAX_SEQ_LEN, MAX_WORD_LEN)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1cFfg0IqFE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "8728a1e6-2eb3-4a1c-8cfc-26604924b527"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   1,  150,  235,   11,   36,   72,   49, 3318,    8, 1977, 4171,  166,\n",
              "         9619, 9619, 7832,    4,  199,    7, 1385, 9619,   67, 1103,    3,    2]),\n",
              " tensor([[24, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 28,  4, 14,  5, 11,  0, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33,  4,  6,  2,  3,  0, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 29,  7,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 16,  4, 21,  2,  6,  8, 15,  2,  8,  5,  0, 32, 32, 32],\n",
              "         [ 1, 33, 14,  2,  7, 10,  3, 19,  0, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1,  3, 12,  7,  4,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 14,  8, 21,  2,  9, 12,  2, 10,  0, 32, 32, 32, 32, 32],\n",
              "         [ 1,  3,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1,  7,  4, 33, 13,  3, 12, 12,  2, 10,  0, 32, 32, 32, 32],\n",
              "         [ 1, 33,  6,  2,  2,  8,  0, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33,  2, 23,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33,  4, 26,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33,  6,  2,  3,  5,  9,  4,  8,  0, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33, 12,  3,  8,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 25,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1,  2, 33, 18,  2, 13,  5,  2, 10,  0, 32, 32, 32, 32, 32],\n",
              "         [ 1,  5,  4,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 13,  6,  2,  3,  5,  2,  0, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33, 25, 33, 22, 25, 22, 22, 22,  0, 32, 32, 32, 32, 32],\n",
              "         [ 1,  8,  2, 23,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33,  4, 26,  7,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 20,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32]]),\n",
              " tensor([ 1,  3, 10,  0,  0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwiiGscn29-V",
        "colab_type": "text"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGPqxgEboFV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpHqwpKNqtcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_fn(data):\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "    sentences, words, tags = zip(*data)\n",
        "\n",
        "    # Merge questions (from tuple of 1D tensor to 2D tensor).\n",
        "    sent_lengths = [len(sent) for sent in sentences]\n",
        "    inputs = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
        "    labels = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
        "    chars = torch.zeros(len(sentences), max(sent_lengths), MAX_WORD_LEN).long()\n",
        "    for i, (sent, lab, ch) in enumerate(zip(sentences, tags, words)):\n",
        "        end = sent_lengths[i]\n",
        "        inputs[i, :end] = sent[:end]\n",
        "        labels[i, :end] = lab[:end]\n",
        "        chars[i, :end] = ch[:end]\n",
        "    return inputs, chars, labels, sent_lengths\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_hY3a7DyhKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_loader = data.DataLoader(train_dataset, BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_data_loader = data.DataLoader(valid_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_data_loader = data.DataLoader(test_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQHLq_P4n3AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = next(iter(train_data_loader))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWf2QvFsgT3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "698830ec-4d34-4aca-a656-c1d87ef40d69"
      },
      "source": [
        "sample[0].shape, sample[1].shape, sample[2].shape, len(sample[3])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 42]), torch.Size([64, 42, 15]), torch.Size([64, 42]), 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q08pzQGp3Ami",
        "colab_type": "text"
      },
      "source": [
        "### Charcter-BiLSTM-CRF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFzphEAGTxad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharBiLSTMCRF(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, char_emb_dim, char_hid_dim, char_vocab_size, tag_vocab_size, sent_pad_token, tag_start_token, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.sent_pad_token = sent_pad_token\n",
        "        self.tag_start_token = tag_start_token\n",
        "        self.tag_vocab_size = tag_vocab_size\n",
        "\n",
        "        self.char_embedding = nn.Embedding(char_vocab_size, char_emb_dim, padding_idx=0)\n",
        "        self.char_lstm = nn.LSTM(char_emb_dim, char_hid_dim, bidirectional=True, batch_first=True)\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim + char_hid_dim,\n",
        "            hid_dim,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.emission = nn.Linear(hid_dim * 2, tag_vocab_size)\n",
        "        self.transition = nn.Parameter(torch.rand(tag_vocab_size, tag_vocab_size))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, sentences, lengths, words, tags):\n",
        "        # sentences => [batch_size, seq_len]\n",
        "        # lengths => [batch_size]\n",
        "        # words => [batch_size, seq_len, word_len]\n",
        "        # tags => [batch_size, seq_len]\n",
        "\n",
        "        char_final_hidden = []\n",
        "        for word in words:\n",
        "            # word => [seq_len, word_len]\n",
        "            char_embed = self.char_embedding(word)\n",
        "            char_embed = self.dropout(char_embed)\n",
        "            # char_embed => [seq_len, word_len, char_emb_dim]\n",
        "\n",
        "            _, (char_hidden, _) = self.char_lstm(char_embed)\n",
        "            # char_hidden => [2, seq_len, char_hid_dim]\n",
        "\n",
        "            # add the final forward and backward hidden states\n",
        "            char_combined = char_hidden[-1, :, :] + char_hidden[-2, :, :]\n",
        "            # char_combined => [seq_len, char_hid_dim]\n",
        "\n",
        "            char_final_hidden.append(char_combined)\n",
        "        \n",
        "        char_encoding = torch.stack(char_final_hidden)\n",
        "        # char_encoding => [batch_size, seq_len, char_hid_dim]\n",
        "\n",
        "        mask = (sentences != self.sent_pad_token).to(device)\n",
        "        # mask => [batch_size, seq_len]\n",
        "\n",
        "        embed = self.embedding(sentences)\n",
        "        embed = self.dropout(embed)\n",
        "        # embed => [batch_size, seq_len, emb_dim]\n",
        "\n",
        "        embed_with_char = torch.cat((embed, char_encoding), dim=-1)\n",
        "        # embed_with_char => [batch_size, seq_len, emb_dim + char_hid_dim]\n",
        "\n",
        "        packed_input = nn.utils.rnn.pack_padded_sequence(embed_with_char, lengths, batch_first=True)\n",
        "        packed_output, _ = self.lstm(packed_input)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
        "        # outputs => [batch_size, seq_len, hid_dim * 2]\n",
        "\n",
        "        combined = torch.cat((outputs[:, :, :self.hid_dim], outputs[:, :, self.hid_dim:]), dim=-1)\n",
        "        combined = self.dropout(combined)\n",
        "        # combined => [batch_size, seq_len, hid_dim * 2]\n",
        "\n",
        "        emission_scores = self.emission(combined)\n",
        "        # emission_scores => [batch_size, seq_len, tag_size]\n",
        "\n",
        "        loss = self.vitebri_loss(tags, mask, emission_scores)\n",
        "        # loss => [batch_size]\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def vitebri_loss(self, tags, mask, emit_scores):\n",
        "        # tags => [batch_size, seq_len]\n",
        "        # mask => [batch_size, seq_len]\n",
        "        # emit_scores => [batch_size, seq_len, tag_size]\n",
        "\n",
        "        batch_size, sent_len = tags.shape\n",
        "\n",
        "        # calculate the ground truth score\n",
        "        score = torch.gather(emit_scores, 2, tags.unsqueeze(2)).squeeze(2)\n",
        "        # emission scores of actual tags\n",
        "        # score => [batch_size, seq_len]\n",
        "\n",
        "        # add the transition scores to the emission scores\n",
        "        # ignore the start token tag score\n",
        "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
        "\n",
        "        # consider only the scores of actual tokens not the padded\n",
        "        gold_scores = (score * mask.type(torch.float)).sum(dim=1)\n",
        "        # gold_scores => [batch_size]\n",
        "\n",
        "        # calculate the scores of the partition (Z)\n",
        "        # tensor to hold the accumulated sequence scores at each time step\n",
        "        # at the inital time step score will be on dim=0\n",
        "        scores_upto_t = emit_scores[:, 0].unsqueeze(1)\n",
        "        # scores_upto_t => [batch_size, 1, tag_size]\n",
        "\n",
        "        for i in range(1, sent_len):\n",
        "            # get the current batch_size\n",
        "            batch_t = mask[:, i].sum()\n",
        "\n",
        "            # get the accumulated scores till now (only the current batch size)\n",
        "            scores_unpad = scores_upto_t[:batch_t]\n",
        "            # scores_unpad => [batch_t, 1, tag_size]\n",
        "\n",
        "            # add the transition scores for this time step\n",
        "            scores_with_trans = emit_scores[:batch_t, i].unsqueeze(1) + self.transition\n",
        "            # scores_with_trans => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            # add to the accumulation\n",
        "            sum_scores = scores_unpad.transpose(1, 2) + scores_with_trans\n",
        "            # sum_scores => [batch_t, tag_size, tag_size]\n",
        "            \n",
        "            # apply the following to overcome the overflow problems\n",
        "            # since the exp(some_big_number) will cause issues \n",
        "            # log( exp(z_k)) = max(z) + log( exp(z_k - max(z)))\n",
        "            # log( exp(z_k)) = log( exp(z_k - c + c))\n",
        "            #                 = log( exp(z_k - c) * exp(c))\n",
        "            #                 = log( exp(z_k - c)) + log(exp(c))\n",
        "            #                 = log( exp(z_k - c)) + c\n",
        "            # by taking c as max(z)\n",
        "            # log( exp(z_k)) = max(z) + log( exp(z_k - max(z))) [log_sum_exp]\n",
        "            # get the maximum score of the current time step\n",
        "            max_t = sum_scores.max(dim=1)[0].unsqueeze(1)\n",
        "            # max_t => [batch_t, 1, tag_size]\n",
        "\n",
        "            sum_scores = sum_scores - max_t\n",
        "            # sum_scores => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            scores_t = max_t + torch.logsumexp(sum_scores, dim=1).unsqueeze(1)\n",
        "            # scores_t => [batch_t, 1, tag_size]\n",
        "\n",
        "            # update the accumulation scores\n",
        "            scores_upto_t = torch.cat((scores_t, scores_upto_t[batch_t:]), dim=0)\n",
        "            # scores_upto_t => [batch_size, 1, tag_size]\n",
        "        \n",
        "        final_scores = scores_upto_t.squeeze(1)\n",
        "        # final_scores => [batch_size, tag_size]\n",
        "\n",
        "        max_final_scores = final_scores.max(dim=-1)[0]\n",
        "        # max_final_scores => [batch_size]\n",
        "\n",
        "        predicted_scores = max_final_scores + torch.logsumexp(final_scores - max_final_scores.unsqueeze(1), dim=1)\n",
        "        # predicted_scores => [batch_size]\n",
        "\n",
        "        vitebri_loss = predicted_scores - gold_scores\n",
        "        # vitebri_loss => [batch_size]\n",
        "\n",
        "        return vitebri_loss\n",
        "    \n",
        "    def predict(self, sentences, lengths, words):\n",
        "        # sentences => [batch_size, seq_len]\n",
        "        # lengths => [batch_size]\n",
        "        # words => [batch_size, seq_len, word_len]\n",
        "\n",
        "        batch_size = sentences.size(0)\n",
        "\n",
        "        char_final_hidden = []\n",
        "        for word in words:\n",
        "            # word => [seq_len, word_len]\n",
        "            char_embed = self.char_embedding(word)\n",
        "            char_embed = self.dropout(char_embed)\n",
        "            # char_embed => [seq_len, word_len, char_emb_dim]\n",
        "\n",
        "            _, (char_hidden, _) = self.char_lstm(char_embed)\n",
        "            # char_hidden => [2, seq_len, char_hid_dim]\n",
        "\n",
        "            # add the final forward and backward hidden states\n",
        "            char_combined = char_hidden[-1, :, :] + char_hidden[-2, :, :]\n",
        "            # char_combined => [seq_len, char_hid_dim]\n",
        "\n",
        "            char_final_hidden.append(char_combined)\n",
        "        \n",
        "        char_encoding = torch.stack(char_final_hidden)\n",
        "        # char_encoding => [batch_size, seq_len, char_hid_dim]\n",
        "\n",
        "        mask = (sentences != self.sent_pad_token).to(device)\n",
        "        # mask => [batch_size, seq_len]\n",
        "\n",
        "        embed = self.embedding(sentences)\n",
        "        embed = self.dropout(embed)\n",
        "        # embed => [batch_size, seq_len, emb_dim]\n",
        "\n",
        "        embed_with_char = torch.cat((embed, char_encoding), dim=-1)\n",
        "        # embed_with_char => [batch_size, seq_len, emb_dim + char_hid_dim]\n",
        "\n",
        "        packed_inp = nn.utils.rnn.pack_padded_sequence(embed_with_char, lengths, batch_first=True)\n",
        "        packed_output, _ = self.lstm(packed_inp)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
        "        # outputs => [batch_size, seq_len, hid_dim * 2]\n",
        "\n",
        "        combined = torch.cat((outputs[:, :, :self.hid_dim], outputs[:, :, self.hid_dim:]), dim=-1)\n",
        "        combined = self.dropout(combined)\n",
        "        # combined => [batch_size, seq_len, hid_dim * 2]\n",
        "\n",
        "        emission_scores = self.emission(combined)\n",
        "        # emission_scores => [batch_size, seq_len, tag_size]\n",
        "\n",
        "        # to store the tags predicted at each time step\n",
        "        # since at the begining every tag is start tag create the list with start tags\n",
        "        tags = [[[self.tag_start_token] for _ in range(self.tag_vocab_size)]] * batch_size\n",
        "        # tags => [batch_size, tag_size, 1]\n",
        "\n",
        "        scores_upto_t = emission_scores[:, 0].unsqueeze(1)\n",
        "        # scores_upto_t => [batch_size, 1, tag_size]\n",
        "\n",
        "        for i in range(1, max(lengths)):\n",
        "            # get the current batch_size\n",
        "            batch_t = mask[:, i].sum()\n",
        "\n",
        "            # get the accumulated scores till now (only the current batch size)\n",
        "            scores_unpad = scores_upto_t[:batch_t]\n",
        "            # scores_unpad => [batch_t, 1, tag_size]\n",
        "\n",
        "            # add the transition scores for this time step\n",
        "            scores_with_trans = emission_scores[:batch_t, i].unsqueeze(1) + self.transition\n",
        "            # scores_with_trans => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            # add to the accumulation\n",
        "            sum_scores = scores_unpad.transpose(1, 2) + scores_with_trans\n",
        "            # sum_scores => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            max_scores_t, max_ids_t = torch.max(sum_scores, dim=1)\n",
        "            max_ids_t = max_ids_t.tolist()\n",
        "            # max_scores_t => [batch_t, tag_size]\n",
        "            # max_ids_t => [batch_t, tag_size]\n",
        "\n",
        "            # add the current time step predicted tags \n",
        "            tags[:batch_t] = [[tags[b][k] + [j] for j, k in enumerate(max_ids_t[b])] for b in range(batch_t)]\n",
        "            \n",
        "            # update the accumulation scores\n",
        "            scores_upto_t = torch.cat((max_scores_t.unsqueeze(1), scores_upto_t[batch_t:]), dim=0)\n",
        "            # scores_upto_t => [batch_size, tag_size]\n",
        "\n",
        "        scores = scores_upto_t.squeeze(1)\n",
        "        # scores => [batch_size, tag_size]\n",
        "\n",
        "        _, max_ids = torch.max(scores, dim=1)\n",
        "        max_ids = max_ids.tolist()\n",
        "        # max_ids => [batch_size]\n",
        "\n",
        "        # tags => [batch_size, tag_size, seq_len]\n",
        "        tags = [tags[b][k] for b, k in enumerate(max_ids)]\n",
        "        # tags => [batch_size, seq_len]\n",
        "\n",
        "        return tags\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEY0Z8WMVmZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "82f63958-f5d1-46ed-f89f-9cc5e4b00084"
      },
      "source": [
        "vocab_size = len(words_vocab)\n",
        "sent_pad_token = words_vocab[words_vocab.PAD]\n",
        "tag_start_token = tags_vocab[tags_vocab.START]\n",
        "emb_dim = 50\n",
        "hid_dim = 200\n",
        "char_emb_dim = 20\n",
        "char_hid_dim = 50\n",
        "char_vocab_size = len(chars_vocab)\n",
        "tag_vocab_size = len(tags_vocab)\n",
        "model = CharBiLSTMCRF(\n",
        "    vocab_size,\n",
        "    emb_dim,\n",
        "    hid_dim,\n",
        "    char_emb_dim,\n",
        "    char_hid_dim,\n",
        "    char_vocab_size,\n",
        "    tag_vocab_size,\n",
        "    sent_pad_token,\n",
        "    tag_start_token\n",
        ")\n",
        "model.to(device)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharBiLSTMCRF(\n",
              "  (char_embedding): Embedding(34, 20, padding_idx=0)\n",
              "  (char_lstm): LSTM(20, 50, batch_first=True, bidirectional=True)\n",
              "  (embedding): Embedding(9620, 50, padding_idx=0)\n",
              "  (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
              "  (emission): Linear(in_features=400, out_features=20, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuu7YjwQt3-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58829053-d142-435b-ec52-4ba9f961651d"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,002,100 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fpc9vWq3EY3",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKhNhP5_uFsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv1kwAoG3IzE",
        "colab_type": "text"
      },
      "source": [
        "### Training Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJQZHAmGuP-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, clip):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    total_sentences = 0\n",
        "\n",
        "    for batch in iterator:\n",
        "        sentences = batch[0].to(device)\n",
        "        words = batch[1].to(device)\n",
        "        tags = batch[2].to(device)\n",
        "        seq_lengths = batch[3]\n",
        "        # sentences => [batch_size, seq_len]\n",
        "        # words => [batch_size, seq_len, word_len]\n",
        "        # tags => [batch_size, seq_len]\n",
        "        # seq_lengths => [batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_loss = model(sentences, seq_lengths, words, tags)\n",
        "        # batch_loss => [batch_size]\n",
        "\n",
        "        loss = batch_loss.mean()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += batch_loss.sum().item()\n",
        "        total_sentences += len(sentences)\n",
        "\n",
        "    return epoch_loss / total_sentences\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeoX6uxx3MVe",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK-UR_62uS0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    total_sentences = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            sentences = batch[0].to(device)\n",
        "            words = batch[1].to(device)\n",
        "            tags = batch[2].to(device)\n",
        "            seq_lengths = batch[3]\n",
        "            # sentences => [batch_size, seq_len]\n",
        "            # words => [batch_size, seq_len, word_len]\n",
        "            # tags => [batch_size, seq_len]\n",
        "            # seq_lengths => [batch_size]\n",
        "\n",
        "            batch_loss = model(sentences, seq_lengths, words, tags)\n",
        "            # batch_loss => [batch_size]\n",
        "\n",
        "            loss = batch_loss.mean()\n",
        "\n",
        "            epoch_loss += batch_loss.sum().item()\n",
        "            total_sentences += len(sentences)\n",
        "        \n",
        "    return epoch_loss / total_sentences\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5urAtI4W3OUf",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8_N8-U6uUtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL5kQHBluWkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "8f85921e-8900-4769-e938-140a81004b11"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 2\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_data_loader, optimizer, CLIP)\n",
        "    valid_loss = evaluate(model, valid_data_loader)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 3m 38s\n",
            "\tTrain Loss: 9.352 | Val. Loss: 1.770\n",
            "Epoch: 02 | Epoch Time: 3m 42s\n",
            "\tTrain Loss: 1.744 | Val. Loss: 1.553\n",
            "Epoch: 03 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 1.559 | Val. Loss: 1.460\n",
            "Epoch: 04 | Epoch Time: 3m 43s\n",
            "\tTrain Loss: 1.481 | Val. Loss: 1.468\n",
            "Epoch: 05 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 1.419 | Val. Loss: 1.477\n",
            "Epoch: 06 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 1.380 | Val. Loss: 1.455\n",
            "Epoch: 07 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 1.346 | Val. Loss: 1.460\n",
            "Epoch: 08 | Epoch Time: 3m 44s\n",
            "\tTrain Loss: 1.329 | Val. Loss: 1.448\n",
            "Epoch: 09 | Epoch Time: 3m 47s\n",
            "\tTrain Loss: 1.302 | Val. Loss: 1.476\n",
            "Epoch: 10 | Epoch Time: 3m 47s\n",
            "\tTrain Loss: 1.277 | Val. Loss: 1.473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIXBCe7S3c3y",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqDAWdc8vVAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5437f65-04f4-418f-b41e-7f27f4c23fbd"
      },
      "source": [
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKC73CrN3Ycb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "247f5a4b-01d0-4a57-fcf6-2e98d336397a"
      },
      "source": [
        "test_loss = evaluate(model, test_data_loader)\n",
        "print(f'Test Loss: {test_loss:.3f}')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cOPRvJ_K4wa",
        "colab_type": "text"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRDAFlHzK6yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_metrics(model, iterator):\n",
        "    model.eval()\n",
        "\n",
        "    fin_outputs = []\n",
        "    fin_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            sentences = batch[0].to(device)\n",
        "            words = batch[1].to(device)\n",
        "            tags = batch[2].to(device)\n",
        "            seq_lengths = batch[3]\n",
        "            # sentences => [batch_size, seq_len]\n",
        "            # words => [batch_size, seq_len, word_len]\n",
        "            # tags => [batch_size, seq_len]\n",
        "            # seq_lengths => [batch_size]\n",
        "\n",
        "            predictions = model.predict(sentences, seq_lengths, words)\n",
        "            # predictions => [batch_size, seq_len]\n",
        "\n",
        "            fin_outputs.extend(predictions)\n",
        "            fin_targets.extend(tags.detach().cpu().numpy().tolist())\n",
        "        \n",
        "    assert len(fin_outputs) == len(fin_targets)\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    trans_trg = mlb.fit_transform(fin_targets)\n",
        "    trans_pred = mlb.transform(fin_outputs)\n",
        "\n",
        "    cf = metrics.classification_report(trans_trg, trans_pred)\n",
        "    print(cf)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-DQzxmmK7_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "4ce9d800-653d-4c0a-9f21-f5b1917460e8"
      },
      "source": [
        "cal_metrics(model, test_data_loader)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      4796\n",
            "           1       1.00      1.00      1.00      4796\n",
            "           2       1.00      1.00      1.00      4796\n",
            "           3       0.93      0.95      0.94      2496\n",
            "           4       0.98      0.95      0.97      1688\n",
            "           5       0.87      0.81      0.84      1623\n",
            "           6       0.92      0.95      0.94      1071\n",
            "           7       0.93      0.91      0.92      1361\n",
            "           8       0.83      0.86      0.85       879\n",
            "           9       0.98      0.93      0.96      1303\n",
            "          10       0.87      0.83      0.85       595\n",
            "          11       0.88      0.81      0.85       395\n",
            "          12       0.25      0.05      0.08        42\n",
            "          13       0.67      0.45      0.54        31\n",
            "          14       0.20      0.04      0.07        25\n",
            "          15       0.38      0.31      0.34        16\n",
            "          16       0.85      0.73      0.79        15\n",
            "          17       0.80      0.33      0.47        12\n",
            "          18       1.00      0.50      0.67         4\n",
            "\n",
            "   micro avg       0.96      0.95      0.96     25944\n",
            "   macro avg       0.81      0.71      0.74     25944\n",
            "weighted avg       0.96      0.95      0.96     25944\n",
            " samples avg       0.97      0.96      0.96     25944\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEH5FeEBt4BY",
        "colab_type": "text"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQOhx3g3lmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(sentence):\n",
        "    if isinstance(sentence, str):\n",
        "        tokens = [words_vocab[words_vocab.START]] + sentence.split() + [words_vocab[words_vocab.END]]\n",
        "    else:\n",
        "        tokens = sentence\n",
        "    \n",
        "    chars = [['<START']] + [['<START>'] + [ch for ch in word] + ['<END>'] for word in tokens[1:-1]] + [['<END>']]\n",
        "\n",
        "    char_seq = []\n",
        "    for word in chars:\n",
        "        word_len = len(word)\n",
        "        # truncate the word if it is greater than max_word_len\n",
        "        if word_len > MAX_WORD_LEN:\n",
        "            word = word[:MAX_WORD_LEN]\n",
        "        # pad the word if it less\n",
        "        else:\n",
        "            pad_length = MAX_WORD_LEN - word_len\n",
        "            word = word + [chars_vocab.PAD] * pad_length\n",
        "        \n",
        "        # convert the chars into numerical format\n",
        "        char_ids = []\n",
        "        for each_char in word: \n",
        "            char_ids.append(chars_vocab[each_char])\n",
        "        char_seq.append(char_ids)\n",
        "\n",
        "    # numericalize\n",
        "    token_ids = [words_vocab[tok] for tok in tokens]\n",
        "    \n",
        "    # seq length\n",
        "    sent_length = [len(token_ids)]\n",
        "\n",
        "    # create tensors\n",
        "    sent_tensor = torch.LongTensor(token_ids).to(device)\n",
        "    sent_tensor = sent_tensor.unsqueeze(0)\n",
        "    # sent_tensor => [1, seq_len]\n",
        "\n",
        "    char_tensor = torch.LongTensor(char_seq).to(device)\n",
        "    char_tensor = char_tensor.unsqueeze(0)\n",
        "    # char_tensor => [1, seq_len, word_len]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model.predict(sent_tensor, sent_length, char_tensor)\n",
        "    \n",
        "    predictions = predictions[0]\n",
        "    predicted_tags = []\n",
        "    for i in predictions:\n",
        "        predicted_tags.append(tags_vocab.id2word(i))\n",
        "    \n",
        "    return tokens, predicted_tags\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUrgvPn1vj0W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "b853475e-6c5e-4bd6-81d2-ebd327926d28"
      },
      "source": [
        "sentence = test_sentences[0]\n",
        "actual_tags = test_tags[0]\n",
        "tokens, predicted_tag_ids = inference(sentence)\n",
        "\n",
        "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
        "for token, pred_tag, actual_tag in zip(tokens, predicted_tag_ids, actual_tags):\n",
        "    correct = '' if pred_tag == actual_tag else ''\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
            "\n",
            "<START>\t\t<START>\t\t\t\t<START>\n",
            "O\t\tO\t\t\t\tThe\n",
            "O\t\tO\t\t\t\toffice\n",
            "O\t\tO\t\t\t\tof\n",
            "O\t\tO\t\t\t\tthe\n",
            "B-gpe\t\tB-gpe\t\t\t\tIsraeli\n",
            "O\t\tO\t\t\t\tprime\n",
            "O\t\tO\t\t\t\tminister\n",
            "O\t\tO\t\t\t\tsays\n",
            "O\t\tO\t\t\t\ta\n",
            "O\t\tO\t\t\t\tvisit\n",
            "O\t\tO\t\t\t\tto\n",
            "B-geo\t\tB-geo\t\t\t\tIsrael\n",
            "O\t\tO\t\t\t\tby\n",
            "O\t\tO\t\t\t\tthe\n",
            "O\t\tO\t\t\t\tforeign\n",
            "O\t\tO\t\t\t\tministers\n",
            "O\t\tO\t\t\t\tof\n",
            "B-geo\t\tB-gpe\t\t\t\tEgypt\n",
            "O\t\tO\t\t\t\tand\n",
            "B-gpe\t\tB-gpe\t\t\t\tJordan\n",
            "O\t\tO\t\t\t\twill\n",
            "O\t\tO\t\t\t\ttake\n",
            "O\t\tO\t\t\t\tplace\n",
            "B-tim\t\tB-tim\t\t\t\tJuly\n",
            "I-tim\t\tI-tim\t\t\t\t25\n",
            "O\t\tO\t\t\t\t,\n",
            "O\t\tO\t\t\t\tnot\n",
            "O\t\tO\t\t\t\tthis\n",
            "O\t\tO\t\t\t\tweek\n",
            "O\t\tO\t\t\t\tas\n",
            "O\t\tO\t\t\t\tpreviously\n",
            "O\t\tO\t\t\t\tplanned\n",
            "O\t\tO\t\t\t\t.\n",
            "<END>\t\t<END>\t\t\t\t<END>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UDJLIFLzlsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "72dbc65b-3f24-4c8a-9a4d-e4f59e5b0270"
      },
      "source": [
        "sentence = test_sentences[10]\n",
        "actual_tags = test_tags[10]\n",
        "tokens, predicted_tag_ids = inference(sentence)\n",
        "\n",
        "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
        "for token, pred_tag, actual_tag in zip(tokens, predicted_tag_ids, actual_tags):\n",
        "    correct = '' if pred_tag == actual_tag else ''\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
            "\n",
            "<START>\t\t<START>\t\t\t\t<START>\n",
            "O\t\tO\t\t\t\tAn\n",
            "B-gpe\t\tB-gpe\t\t\t\tIraqi\n",
            "O\t\tO\t\t\t\tmilitant\n",
            "O\t\tO\t\t\t\tgroup\n",
            "O\t\tO\t\t\t\t(\n",
            "O\t\tO\t\t\t\tthe\n",
            "B-org\t\tB-org\t\t\t\tIslamic\n",
            "I-org\t\tI-org\t\t\t\tArmy\n",
            "O\t\tO\t\t\t\tof\n",
            "B-geo\t\tB-geo\t\t\t\tIraq\n",
            "O\t\tO\t\t\t\t)\n",
            "O\t\tO\t\t\t\tposted\n",
            "O\t\tO\t\t\t\ta\n",
            "O\t\tO\t\t\t\tvideo\n",
            "O\t\tO\t\t\t\ton\n",
            "O\t\tO\t\t\t\tthe\n",
            "O\t\tO\t\t\t\tInternet\n",
            "B-tim\t\tB-tim\t\t\t\ttoday\n",
            "O\t\tO\t\t\t\tthat\n",
            "O\t\tO\t\t\t\tshowed\n",
            "O\t\tO\t\t\t\ta\n",
            "O\t\tO\t\t\t\tblindfolded\n",
            "O\t\tO\t\t\t\tman\n",
            "O\t\tO\t\t\t\tbeing\n",
            "O\t\tO\t\t\t\tshot\n",
            "O\t\tO\t\t\t\tin\n",
            "O\t\tO\t\t\t\tthe\n",
            "O\t\tO\t\t\t\tback\n",
            "O\t\tO\t\t\t\tof\n",
            "O\t\tO\t\t\t\tthe\n",
            "O\t\tO\t\t\t\thead\n",
            "O\t\tO\t\t\t\t.\n",
            "<END>\t\t<END>\t\t\t\t<END>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jyhMAl63I7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "0e30f265-00b0-46ee-837d-b5f94afcd5c6"
      },
      "source": [
        "sentence = \"I like to live in New York\"\n",
        "tokens, predicted_tag_ids = inference(sentence)\n",
        "\n",
        "print(\"Pred. Tag\\tToken\\n\")\n",
        "for token, pred_tag in zip(tokens[1:-1], predicted_tag_ids[1:-1]):\n",
        "    print(f\"{pred_tag}\\t\\t{token}\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred. Tag\tToken\n",
            "\n",
            "O\t\tI\n",
            "O\t\tlike\n",
            "O\t\tto\n",
            "O\t\tlive\n",
            "O\t\tin\n",
            "B-geo\t\tNew\n",
            "I-geo\t\tYork\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srjLeOA53aRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "d8a84a44-2aa1-45cf-d159-953b7b7fe9ae"
      },
      "source": [
        "sentence = \"My dream is to work at Google\"\n",
        "tokens, predicted_tag_ids = inference(sentence)\n",
        "\n",
        "print(\"Pred. Tag\\tToken\\n\")\n",
        "for token, pred_tag in zip(tokens[1:-1], predicted_tag_ids[1:-1]):\n",
        "    print(f\"{pred_tag}\\t\\t{token}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred. Tag\tToken\n",
            "\n",
            "O\t\tMy\n",
            "O\t\tdream\n",
            "O\t\tis\n",
            "O\t\tto\n",
            "O\t\twork\n",
            "O\t\tat\n",
            "B-org\t\tGoogle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFkVZrIf38D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}