{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER tagging with Transformer-CRF.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOjqbQlRPu1cHyYVgjHfhPk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fclassification/applications/classification/ner_tagging/NER%20tagging%20with%20Transformer-CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpB3DqsGkE9v",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "7de92bd1-b188-4f74-bd41-42bcba8244d4"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a0b976b7-9fc1-4107-829a-a65d2e54789e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a0b976b7-9fc1-4107-829a-a65d2e54789e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ravirajag\",\"key\":\"7c9b32c3baf1bd5e404db6e4e281fc5c\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xVqLRrMkjRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psDd3FOBkkyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ef5d7fb1-2fca-46e6-eea2-96d484073bbd"
      },
      "source": [
        "!kaggle datasets download -d abhinavwalia95/entity-annotated-corpus"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading entity-annotated-corpus.zip to /content\n",
            " 95% 25.0M/26.4M [00:01<00:00, 21.2MB/s]\n",
            "100% 26.4M/26.4M [00:01<00:00, 23.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-XO9tKBkmQ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d0ce31cc-e0ff-42a7-c12d-9d28a669df00"
      },
      "source": [
        "!unzip entity-annotated-corpus.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  entity-annotated-corpus.zip\n",
            "  inflating: ner.csv                 \n",
            "  inflating: ner_dataset.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtEHsMhf5Vgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "import random\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuJgpe8Vj18t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b79f466-ab81-4ef0-e6d5-cdac2cad1d62"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb5295e9480>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSFvcX4_j4WI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6591d9ed-7720-4081-d8ef-0b7cf4c93898"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTWCWneMk0ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datafile = 'ner_dataset.csv'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9gFnPyxk2eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(datafile, encoding=\"latin1\", error_bad_lines=False)\n",
        "df = df.fillna(method='ffill')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ7x9PZPk-TT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "4ff8af80-bf18-4c78-fea9-5a745187afd6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0de4x-2k_Pb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "d768652b-7a2d-4205-f75a-ee01d37b1872"
      },
      "source": [
        "tags = list(df.Tag.unique())\n",
        "tags"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-geo',\n",
              " 'B-gpe',\n",
              " 'B-per',\n",
              " 'I-geo',\n",
              " 'B-org',\n",
              " 'I-org',\n",
              " 'B-tim',\n",
              " 'B-art',\n",
              " 'I-art',\n",
              " 'I-per',\n",
              " 'I-gpe',\n",
              " 'I-tim',\n",
              " 'B-nat',\n",
              " 'B-eve',\n",
              " 'I-eve',\n",
              " 'I-nat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myhr3FzwlCV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "e3df5bfa-d666-4803-8a3a-64ab34998839"
      },
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "sns.countplot(df.Tag.values)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb4d3fd7f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPOFcXZjlEme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0f2cf98-0fec-4c55-c9f4-17d91f0f9af1"
      },
      "source": [
        "num_tags = len(tags)\n",
        "num_tags"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsSzdy0mlJyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agg_func = lambda s: [(w, t) for w, p, t in zip(s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist())]\n",
        "group = df.groupby(\"Sentence #\").apply(agg_func)\n",
        "lines = [s for s in group]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmH_0Ue-ltmr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "c4a18fbd-19fe-42e1-c65e-dd868dc11a1c"
      },
      "source": [
        "lines[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Thousands', 'O'),\n",
              " ('of', 'O'),\n",
              " ('demonstrators', 'O'),\n",
              " ('have', 'O'),\n",
              " ('marched', 'O'),\n",
              " ('through', 'O'),\n",
              " ('London', 'B-geo'),\n",
              " ('to', 'O'),\n",
              " ('protest', 'O'),\n",
              " ('the', 'O'),\n",
              " ('war', 'O'),\n",
              " ('in', 'O'),\n",
              " ('Iraq', 'B-geo'),\n",
              " ('and', 'O'),\n",
              " ('demand', 'O'),\n",
              " ('the', 'O'),\n",
              " ('withdrawal', 'O'),\n",
              " ('of', 'O'),\n",
              " ('British', 'B-gpe'),\n",
              " ('troops', 'O'),\n",
              " ('from', 'O'),\n",
              " ('that', 'O'),\n",
              " ('country', 'O'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ5LN3Kmluwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [['<start>'] + [tokens[0] for tokens in line] + ['<end>'] for line in lines]\n",
        "tags = [['<start>'] + [tokens[1] for tokens in line] + ['<end>'] for line in lines]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv2_Xhc0lxEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b53df19-9764-47c2-ce45-8ae351b953ff"
      },
      "source": [
        "len(sentences), len(tags)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47959, 47959)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK7xat1GlyRu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "936ddb15-5e5e-4012-edea-1a0715698445"
      },
      "source": [
        "sen_lengths = [len(sent) for sent in sentences]\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.countplot(sen_lengths)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb4d4015c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgHhLr7Hl0Fr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d34547e1-2780-473c-e3a3-5bfd68ad3067"
      },
      "source": [
        "train_sentences, valid_sentences, train_tags, valid_tags = train_test_split(sentences, tags, test_size=0.2, random_state=42)\n",
        "valid_sentences, test_sentences, valid_tags, test_tags = train_test_split(valid_sentences, valid_tags, test_size=0.5, random_state=42)\n",
        "len(train_sentences), len(valid_sentences), len(test_sentences)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38367, 4796, 4796)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP8B2IywV7VL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.idx = 0\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.word2idx[word] = self.idx\n",
        "            self.idx2word[self.idx] = word\n",
        "            self.idx += 1\n",
        "\n",
        "    def __call__(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            return self.word2idx['<unk>']\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USO8AkKfV-ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(data, threshold=5, is_tags=False):\n",
        "    counter = Counter(chain(*data))\n",
        "\n",
        "    # If the word frequency is less than 'threshold', then the word is discarded.\n",
        "    words = [word for word, cnt in counter.items() if cnt >= threshold]\n",
        "\n",
        "    # Create a vocab wrapper and add some special tokens.\n",
        "    vocab = Vocabulary()\n",
        "    vocab.add_word('<pad>')\n",
        "    vocab.add_word('<start>')\n",
        "    vocab.add_word('<end>')\n",
        "    if not is_tags:\n",
        "        vocab.add_word('<unk>')\n",
        "\n",
        "    # Add the words to the vocabulary.\n",
        "    for i, word in enumerate(words):\n",
        "        vocab.add_word(word)\n",
        "    return vocab\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKTbsp9wmdJf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e28fc4f-37c7-4379-a97c-071c797976f5"
      },
      "source": [
        "words_vocab = build_vocab(train_sentences)\n",
        "tags_vocab = build_vocab(train_tags, is_tags=True)\n",
        "len(tags_vocab)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqQ6pmQii6pq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8293ff73-4975-45c5-91dc-b49d6cdf5c07"
      },
      "source": [
        "tags_vocab.word2idx.keys()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['<pad>', '<start>', '<end>', 'B-geo', 'I-geo', 'O', 'B-tim', 'I-tim', 'B-org', 'B-per', 'I-per', 'B-gpe', 'I-org', 'B-art', 'B-eve', 'I-eve', 'I-gpe', 'B-nat', 'I-nat', 'I-art'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGuyKztDmgwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NERDataset(data.Dataset):\n",
        "    def __init__(self, sentences, tags):\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        sentence = self.sentences[item]\n",
        "        tag = self.tags[item]\n",
        "        tokens, tags = [], []\n",
        "\n",
        "        for word, t in zip(sentence, tag):\n",
        "            tokens.append(words_vocab(word))\n",
        "            tags.append(tags_vocab(t))\n",
        "\n",
        "        return torch.LongTensor(tokens), torch.LongTensor(tags)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnMzQGMXmjWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = NERDataset(train_sentences, train_tags)\n",
        "valid_dataset = NERDataset(valid_sentences, valid_tags)\n",
        "test_dataset = NERDataset(test_sentences, test_tags)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5s7adCAmlgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "outputId": "d0746b64-b6ee-49ef-e132-ed793850c730"
      },
      "source": [
        "train_sentences[0], train_tags[0], train_dataset[0]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['<start>',\n",
              "  'South',\n",
              "  'Korea',\n",
              "  \"'s\",\n",
              "  'government',\n",
              "  'Tuesday',\n",
              "  'also',\n",
              "  'unveiled',\n",
              "  'a',\n",
              "  'so-called',\n",
              "  'Green',\n",
              "  'New',\n",
              "  'Job',\n",
              "  'Creation',\n",
              "  'Plan',\n",
              "  ',',\n",
              "  'expected',\n",
              "  'to',\n",
              "  'create',\n",
              "  '9,60,000',\n",
              "  'new',\n",
              "  'jobs',\n",
              "  '.',\n",
              "  '<end>'],\n",
              " ['<start>',\n",
              "  'B-geo',\n",
              "  'I-geo',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-tim',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  '<end>'],\n",
              " (tensor([ 1,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  3,  3, 15, 16, 17, 18,\n",
              "          19,  3, 20, 21, 22,  2]),\n",
              "  tensor([1, 3, 4, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUBpkEYimnJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x3Njl5cmsQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_fn(data):\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "    sentences, tags = zip(*data)\n",
        "\n",
        "    # Merge questions (from tuple of 1D tensor to 2D tensor).\n",
        "    sent_lengths = [len(sent) for sent in sentences]\n",
        "    inputs = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
        "    labels = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
        "    \n",
        "    for i, (sent, lab) in enumerate(zip(sentences, tags)):\n",
        "        end = sent_lengths[i]\n",
        "        inputs[i, :end] = sent[:end]\n",
        "        labels[i, :end] = lab[:end]\n",
        "\n",
        "    return inputs, labels, sent_lengths"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjKowgYLmuOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_loader = data.DataLoader(train_dataset, BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_data_loader = data.DataLoader(valid_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_data_loader = data.DataLoader(test_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s68saqLOmwFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1576c28a-293d-46d9-ebc7-8dd3310b15a0"
      },
      "source": [
        "sample = next(iter(train_data_loader))\n",
        "sample[0].shape, sample[1].shape, len(sample[2])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 42]), torch.Size([128, 42]), 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uamar7D1myo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the positional encoding.\n",
        "    There are other ways of implementing positional encoding.\n",
        "    Below mentioned is the way where the positional encoding is fixed.\n",
        "    Other way is to make that as a learnable using: nn.Embedding(max_len, d_model)\n",
        "    Paper claims there is not much of a difference between either ways.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, dropout, max_len=1000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000) / d_model))\n",
        "\n",
        "        # pe(pos, 2i) = sin(pos / (10000 ^ (2i/d_model)))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "\n",
        "        # pe(pos, 2i+1) = cos(pos / (10000 ^ (2i/d_model)))\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        # pe => [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x => [batch_size, seq_len, d_model]\n",
        "        \n",
        "        # get the positional embeddings of word and add it\n",
        "        x = x + self.pe[:, :x.shape[1], :]\n",
        "        # x => [batch_size, seq_len, d_model]\n",
        "\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ_JxPkBZ6ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the self-attention layer.\n",
        "    This is the core of the transformer model.\n",
        "    There are three kinds of self-attention in transformer:\n",
        "        > Encoder - Encoder: Does the self-attention on the src sentence\n",
        "        > Decoder - Decoder: Does the self-attention on the trg sentence\n",
        "        > Encoder - Decoder: Attends to the src sentence while decoding a particular word\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, n_heads, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        assert d_model % n_heads == 0, \"Number of attention heads must be a factor of d_model\"\n",
        "        # in paper d_model = 512, n_heads = 8\n",
        "\n",
        "        # query, key, value weight matrices\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "        # linear layer to be applied after concating the attention head outputs\n",
        "        self.fc = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # scale factor to be applied in calculation of self-attention\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([d_model // n_heads])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        # query => [batch_size, seq_len, d_model]\n",
        "        # key => [batch_size, seq_len, d_model]\n",
        "        # value => [batch_size, seq_len, d_model]\n",
        "        # mask => [batch_size, 1, seq_len(query), seq_len(key)]\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "        hid_dim = query.shape[2]\n",
        "        assert hid_dim == self.d_model, \"Hidden dimensions must match\"\n",
        "\n",
        "        Q = self.w_q(query)\n",
        "        K = self.w_k(key)\n",
        "        V = self.w_v(value)\n",
        "        # Q, K, V => [batch_size, seq_len, d_model]\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, hid_dim // self.n_heads).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, hid_dim // self.n_heads).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, hid_dim // self.n_heads).permute(0, 2, 1, 3)\n",
        "        # Q, K, V => [batch_size, n_heads, seq_len, head_dim]\n",
        "\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        # energy => [batch_size, n_heads, seq_len(query), seq_len(key)]\n",
        "\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "        attention = self.drop(attention)\n",
        "        # attention => [batch_size, n_heads, seq_len(query), seq_len(key)]\n",
        "\n",
        "        weighted = torch.matmul(attention, V)\n",
        "        # weighted => [batch_size, n_heads, seq_len(query), head_dim]\n",
        "\n",
        "        weighted = weighted.permute(0, 2, 1, 3)\n",
        "        # weighted => [batch_size, seq_len(query), n_heads, head_dim]\n",
        "\n",
        "        weighted = weighted.contiguous()\n",
        "        weighted = weighted.view(batch_size, -1, hid_dim)\n",
        "        # weighted => [batch_size, seq_len(query), d_model]\n",
        "\n",
        "        output = self.fc(weighted)\n",
        "        # output => [batch_size, seq_len(query), d_model]\n",
        "\n",
        "        return output, attention"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hagxiCGnZ-QR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the Position wise feed forward layer.\n",
        "    It is a simple linear layer that project the input to higher dimension\n",
        "    and then back project to the dimension feasible to the model.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, hidden_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(d_model, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        # input => [batch_size, seq_len, d_model]\n",
        "\n",
        "        x = self.dropout(torch.relu(self.fc1(input)))\n",
        "        # x => [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        out = self.fc2(x)\n",
        "        # out => [batch_size, seq_len, d_model]\n",
        "\n",
        "        return out"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_n88yDVaARI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Implement the single encoder block.\n",
        "    There are 6 encoder blocks in transformer (according to the paper).\n",
        "    Each encoder block encapsulates self-attention, positionwise feedforward layer\n",
        "    and then the residual connections across each layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, n_heads, pff_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.pff_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.self_attention = SelfAttention(d_model, n_heads, dropout)\n",
        "        self.pff = PositionWiseFeedForward(d_model, pff_dim, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, src, src_mask):\n",
        "        # src => [batch_size, seq_len, d_model]\n",
        "        # src_mask => [batch_size, 1(n_heads), seq_len(query), seq_len(key)]\n",
        "\n",
        "        # self_attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "        # residual connection with layer norm\n",
        "        src = self.self_attention_layer_norm(src + self.dropout(_src))\n",
        "        # src => [batch_size, seq_len, d_model]\n",
        "\n",
        "        # positionwise feed forward\n",
        "        _src = self.pff(src)\n",
        "\n",
        "        # residual connection with layer norm\n",
        "        src = self.pff_layer_norm(src + self.dropout(_src))\n",
        "        # src => [batch_size, seq_len, d_model]\n",
        "\n",
        "        return src"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLzMK6oqaDbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the encoder.\n",
        "    It takes the input and applies the word embedding, position embedding\n",
        "    for each word and then it is passed through the encoder blocks.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, d_model, n_layers, n_heads, pff_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, d_model)\n",
        "        self.pos_embedding = PositionalEncoding(d_model, dropout)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, n_heads, pff_dim, dropout) for _ in range(n_layers)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, src, src_mask):\n",
        "        # src => [batch_size, seq_len]\n",
        "        # src_mask => [batch_size, 1, seq_len(query), seq_len(key)]\n",
        "\n",
        "        word_embedding = self.tok_embedding(src)\n",
        "        # word_embedding => [batch_size, seq_len, d_model]\n",
        "\n",
        "        position_embedding = self.pos_embedding(word_embedding)\n",
        "\n",
        "        src = self.dropout(position_embedding)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            # src => [batch_size, seq_len, d_model]\n",
        "\n",
        "        return src"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADOVfFouaoU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the transformer.\n",
        "    It encapsulates the encoder and decoder. Inputs to encoder & decoder are padded\n",
        "    to make batch processing feasible. While performing attention certain parts of\n",
        "    the input need not be attended. This will taken care by input masks. Also while\n",
        "    decoding a word at a certain position, it can only attend to the inputs present\n",
        "    to the left side of it, not the right(future) inputs. So the decoder input masking\n",
        "    contains an extra step, for each input it masks the inputs right-side of it.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, src_pad_idx, d_model, tag_vocab_size, tag_start_token):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = nn.Linear(d_model, tag_vocab_size)\n",
        "        self.transition = nn.Parameter(torch.rand(tag_vocab_size, tag_vocab_size))\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.tag_start_token = tag_start_token\n",
        "        self.tag_vocab_size = tag_vocab_size\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        # src => [batch_size, src_len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2).to(device)\n",
        "        # src_mask => [batch_size, 1, 1, src_len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    def forward(self, src, tags):\n",
        "        # src => [batch_size, src_len]\n",
        "        # tags => [batch_size, trg_len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        # src_mask => [batch_size, 1, 1, src_len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        # enc_src => [batch_size, src_len, d_model]\n",
        "\n",
        "        emission_scores = self.decoder(enc_src)\n",
        "        \n",
        "        mask = (src != self.src_pad_idx).to(device)\n",
        "        loss = self.vitebri_loss(tags, mask, emission_scores)\n",
        "        # loss => [batch_size]\n",
        "\n",
        "        return loss\n",
        "    \n",
        "    def vitebri_loss(self, tags, mask, emit_scores):\n",
        "        # tags => [batch_size, seq_len]\n",
        "        # mask => [batch_size, seq_len]\n",
        "        # emit_scores => [seq_len, batch_size, tag_size]\n",
        "\n",
        "        batch_size, sent_len = tags.shape\n",
        "\n",
        "        # calculate the ground truth score\n",
        "        score = torch.gather(emit_scores, 2, tags.unsqueeze(2)).squeeze(2)\n",
        "        # emission scores of actual tags\n",
        "        # score => [batch_size, seq_len]\n",
        "\n",
        "        # add the transition scores to the emission scores\n",
        "        # ignore the start token tag score\n",
        "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
        "\n",
        "        # consider only the scores of actual tokens not the padded\n",
        "        gold_scores = (score * mask.type(torch.float)).sum(dim=1)\n",
        "        # gold_scores => [batch_size]\n",
        "\n",
        "        # calculate the scores of the partition (Z)\n",
        "        # tensor to hold the accumulated sequence scores at each time step\n",
        "        # at the inital time step score will be on dim=0\n",
        "        scores_upto_t = emit_scores[:, 0].unsqueeze(1)\n",
        "        # scores_upto_t => [batch_size, 1, tag_size]\n",
        "\n",
        "        for i in range(1, sent_len):\n",
        "            # get the current batch_size\n",
        "            batch_t = mask[:, i].sum()\n",
        "\n",
        "            # get the accumulated scores till now (only the current batch size)\n",
        "            scores_unpad = scores_upto_t[:batch_t]\n",
        "            # scores_unpad => [batch_t, 1, tag_size]\n",
        "\n",
        "            # add the transition scores for this time step\n",
        "            scores_with_trans = emit_scores[:batch_t, i].unsqueeze(1) + self.transition\n",
        "            # scores_with_trans => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            # add to the accumulation\n",
        "            sum_scores = scores_unpad.transpose(1, 2) + scores_with_trans\n",
        "            # sum_scores => [batch_t, tag_size, tag_size]\n",
        "            \n",
        "            # apply the following to overcome the overflow problems\n",
        "            # since the exp(some_big_number) will cause issues \n",
        "            # log( exp(z_k)) = max(z) + log( exp(z_k - max(z)))\n",
        "            # log( exp(z_k)) = log( exp(z_k - c + c))\n",
        "            #                 = log( exp(z_k - c) * exp(c))\n",
        "            #                 = log( exp(z_k - c)) + log(exp(c))\n",
        "            #                 = log( exp(z_k - c)) + c\n",
        "            # by taking c as max(z)\n",
        "            # log( exp(z_k)) = max(z) + log( exp(z_k - max(z))) [log_sum_exp]\n",
        "            # get the maximum score of the current time step\n",
        "            max_t = sum_scores.max(dim=1)[0].unsqueeze(1)\n",
        "            # max_t => [batch_t, 1, tag_size]\n",
        "\n",
        "            sum_scores = sum_scores - max_t\n",
        "            # sum_scores => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            scores_t = max_t + torch.logsumexp(sum_scores, dim=1).unsqueeze(1)\n",
        "            # scores_t => [batch_t, 1, tag_size]\n",
        "\n",
        "            # update the accumulation scores\n",
        "            scores_upto_t = torch.cat((scores_t, scores_upto_t[batch_t:]), dim=0)\n",
        "            # scores_upto_t => [batch_size, 1, tag_size]\n",
        "        \n",
        "        final_scores = scores_upto_t.squeeze(1)\n",
        "        # final_scores => [batch_size, tag_size]\n",
        "\n",
        "        max_final_scores = final_scores.max(dim=-1)[0]\n",
        "        # max_final_scores => [batch_size]\n",
        "\n",
        "        predicted_scores = max_final_scores + torch.logsumexp(final_scores - max_final_scores.unsqueeze(1), dim=1)\n",
        "        # predicted_scores => [batch_size]\n",
        "\n",
        "        vitebri_loss = predicted_scores - gold_scores\n",
        "        # vitebri_loss => [batch_size]\n",
        "\n",
        "        return vitebri_loss\n",
        "    \n",
        "    def predict(self, src, lengths):\n",
        "        # sentences => [batch_size, seq_len]\n",
        "\n",
        "        batch_size = src.size(0)\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        # src_mask => [batch_size, 1, 1, src_len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        # enc_src => [batch_size, src_len, d_model]\n",
        "\n",
        "        emission_scores = self.decoder(enc_src)\n",
        "        \n",
        "        mask = (src != self.src_pad_idx).to(device)\n",
        "        # mask => [batch_size, seq_len]\n",
        "\n",
        "        # to store the tags predicted at each time step\n",
        "        # since at the begining every tag is start tag create the list with start tags\n",
        "        tags = [[[self.tag_start_token] for _ in range(self.tag_vocab_size)]] * batch_size\n",
        "        # tags => [batch_size, tag_size, 1]\n",
        "\n",
        "        scores_upto_t = emission_scores[:, 0].unsqueeze(1)\n",
        "        # scores_upto_t => [batch_size, 1, tag_size]\n",
        "\n",
        "        for i in range(1, max(lengths)):\n",
        "            # get the current batch_size\n",
        "            batch_t = mask[:, i].sum()\n",
        "\n",
        "            # get the accumulated scores till now (only the current batch size)\n",
        "            scores_unpad = scores_upto_t[:batch_t]\n",
        "            # scores_unpad => [batch_t, 1, tag_size]\n",
        "\n",
        "            # add the transition scores for this time step\n",
        "            scores_with_trans = emission_scores[:batch_t, i].unsqueeze(1) + self.transition\n",
        "            # scores_with_trans => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            # add to the accumulation\n",
        "            sum_scores = scores_unpad.transpose(1, 2) + scores_with_trans\n",
        "            # sum_scores => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            max_scores_t, max_ids_t = torch.max(sum_scores, dim=1)\n",
        "            max_ids_t = max_ids_t.tolist()\n",
        "            # max_scores_t => [batch_t, tag_size]\n",
        "            # max_ids_t => [batch_t, tag_size]\n",
        "\n",
        "            # add the current time step predicted tags \n",
        "            tags[:batch_t] = [[tags[b][k] + [j] for j, k in enumerate(max_ids_t[b])] for b in range(batch_t)]\n",
        "            \n",
        "            # update the accumulation scores\n",
        "            scores_upto_t = torch.cat((max_scores_t.unsqueeze(1), scores_upto_t[batch_t:]), dim=0)\n",
        "            # scores_upto_t => [batch_size, tag_size]\n",
        "\n",
        "        scores = scores_upto_t.squeeze(1)\n",
        "        # scores => [batch_size, tag_size]\n",
        "\n",
        "        _, max_ids = torch.max(scores, dim=1)\n",
        "        max_ids = max_ids.tolist()\n",
        "        # max_ids => [batch_size]\n",
        "\n",
        "        # tags => [batch_size, tag_size, seq_len]\n",
        "        tags = [tags[b][k] for b, k in enumerate(max_ids)]\n",
        "        # tags => [batch_size, seq_len]\n",
        "\n",
        "        return tags\n",
        "\n"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o849z2I7m5e2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_model = 128\n",
        "pff_dim = 256\n",
        "n_heads = 8\n",
        "n_layers = 3\n",
        "input_dim = len(words_vocab)\n",
        "output_dim = 15\n",
        "dropout = 0.4\n",
        "src_pad_idx = words_vocab('<pad>')\n",
        "tag_start_id = tags_vocab('<start>')\n",
        "output_dim = len(tags_vocab)\n",
        "\n",
        "encoder = Encoder(input_dim, d_model, n_layers, n_heads, pff_dim, dropout)\n",
        "model = Transformer(encoder, src_pad_idx, d_model, output_dim, tag_start_id)\n",
        "model = model.to(device)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGOBN3JbnJoc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a43b8546-e839-4a1e-e0cc-68f0c5892b9e"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(9620, 128)\n",
              "    (pos_embedding): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.4, inplace=False)\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attention_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): SelfAttention(\n",
              "          (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (drop): Dropout(p=0.4, inplace=False)\n",
              "          (fc): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (pff): PositionWiseFeedForward(\n",
              "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
              "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
              "          (dropout): Dropout(p=0.4, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.4, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attention_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): SelfAttention(\n",
              "          (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (drop): Dropout(p=0.4, inplace=False)\n",
              "          (fc): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (pff): PositionWiseFeedForward(\n",
              "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
              "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
              "          (dropout): Dropout(p=0.4, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.4, inplace=False)\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attention_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): SelfAttention(\n",
              "          (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (drop): Dropout(p=0.4, inplace=False)\n",
              "          (fc): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (pff): PositionWiseFeedForward(\n",
              "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
              "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
              "          (dropout): Dropout(p=0.4, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.4, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.4, inplace=False)\n",
              "  )\n",
              "  (decoder): Linear(in_features=128, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSfGHD8TnNOf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b240d4a9-3302-4f47-9b6b-572b8566fabc"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,631,780 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNXzvmLRnO0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZTFoOUInWbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_accuracy(preds, y, tag_pad_idx):\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True)\n",
        "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
        "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
        "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]]).to(device)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ML0y33OnYvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in iterator:\n",
        "        text = batch[0].to(device)\n",
        "        tags = batch[1].to(device)\n",
        "        # text => [seq_len, batch_size]\n",
        "        # tags => [seq_len, batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_loss = model(text, tags)\n",
        "\n",
        "        loss = torch.mean(batch_loss)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    return epoch_loss / len(iterator)\n"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVQeTJkWoc54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch[0].to(device)\n",
        "            tags = batch[1].to(device)\n",
        "            # text => [seq_len, batch_size]\n",
        "            # tags => [seq_len, batch_size]\n",
        "\n",
        "            batch_loss = model(text, tags)\n",
        "            loss = torch.mean(batch_loss)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "    \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzaTO4oHov6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RULU606Io4-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "outputId": "b9fd3d06-074c-42f2-e469-121f295ecaa8"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "CLIP = 2\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_data_loader, optimizer, CLIP)\n",
        "    valid_loss = evaluate(model, valid_data_loader)\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')\n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 38s\n",
            "\tTrain Loss: 26.499 | Val. Loss: 19.326\n",
            "Epoch: 02 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 18.042 | Val. Loss: 14.634\n",
            "Epoch: 03 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 14.283 | Val. Loss: 13.913\n",
            "Epoch: 04 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 13.602 | Val. Loss: 13.400\n",
            "Epoch: 05 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 13.187 | Val. Loss: 13.033\n",
            "Epoch: 06 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 9.962 | Val. Loss: 7.210\n",
            "Epoch: 07 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 6.476 | Val. Loss: 5.110\n",
            "Epoch: 08 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 5.430 | Val. Loss: 4.831\n",
            "Epoch: 09 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 5.084 | Val. Loss: 4.634\n",
            "Epoch: 10 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 4.806 | Val. Loss: 4.281\n",
            "Epoch: 11 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 4.532 | Val. Loss: 4.039\n",
            "Epoch: 12 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 4.293 | Val. Loss: 3.800\n",
            "Epoch: 13 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 4.073 | Val. Loss: 3.653\n",
            "Epoch: 14 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 3.788 | Val. Loss: 3.235\n",
            "Epoch: 15 | Epoch Time: 0m 38s\n",
            "\tTrain Loss: 3.584 | Val. Loss: 3.205\n",
            "Epoch: 16 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 3.450 | Val. Loss: 3.095\n",
            "Epoch: 17 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 3.345 | Val. Loss: 3.168\n",
            "Epoch: 18 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 3.252 | Val. Loss: 3.004\n",
            "Epoch: 19 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 3.169 | Val. Loss: 3.072\n",
            "Epoch: 20 | Epoch Time: 0m 38s\n",
            "\tTrain Loss: 3.109 | Val. Loss: 2.973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJX4uD6SpVsl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "23a08af4-f78a-4a73-ef70-fb68ce34da6f"
      },
      "source": [
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IasbGEWqbbD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "914713d4-498b-407c-8d18-698033962ac4"
      },
      "source": [
        "test_loss = evaluate(model, test_data_loader)\n",
        "print(f'Test Loss: {test_loss:.3f}')\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 2.975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjQXOKV4rMUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(sentence):\n",
        "    if isinstance(sentence, str):\n",
        "        tokens = [words_vocab('<start>')] + sentence.split() + [words_vocab('<end>')]\n",
        "    else:\n",
        "        tokens = sentence\n",
        "    \n",
        "    # numericalize\n",
        "    token_ids = [words_vocab(tok) for tok in tokens]\n",
        "    # seq length\n",
        "    sent_length = [len(token_ids)]\n",
        "\n",
        "    # create tensors\n",
        "    sent_tensor = torch.LongTensor(token_ids).to(device)\n",
        "    sent_tensor = sent_tensor.unsqueeze(0)\n",
        "    # sent_tensor => [1, seq_len]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model.predict(sent_tensor, sent_length)\n",
        "    \n",
        "    predictions = predictions[0]\n",
        "    predicted_tags = []\n",
        "    for i in predictions:\n",
        "        predicted_tags.append(tags_vocab.idx2word[i])\n",
        "    \n",
        "    return tokens, predicted_tags"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx7q_RTNtOju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "ae0611cc-4193-44b6-dafa-489006518849"
      },
      "source": [
        "sentence = test_sentences[0]\n",
        "actual_tags = test_tags[0]\n",
        "tokens, predicted_tag_ids = inference(sentence)\n",
        "\n",
        "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
        "for token, pred_tag, actual_tag in zip(tokens, predicted_tag_ids, actual_tags):\n",
        "    correct = '' if pred_tag == actual_tag else ''\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
            "\n",
            "<start>\t\t<start>\t\t\t\t<start>\n",
            "O\t\tO\t\t\t\tThe\n",
            "O\t\tO\t\t\t\toffice\n",
            "O\t\tO\t\t\t\tof\n",
            "O\t\tO\t\t\t\tthe\n",
            "B-gpe\t\tB-gpe\t\t\t\tIsraeli\n",
            "O\t\tO\t\t\t\tprime\n",
            "O\t\tO\t\t\t\tminister\n",
            "O\t\tO\t\t\t\tsays\n",
            "O\t\tO\t\t\t\ta\n",
            "O\t\tO\t\t\t\tvisit\n",
            "O\t\tO\t\t\t\tto\n",
            "B-geo\t\tB-geo\t\t\t\tIsrael\n",
            "O\t\tO\t\t\t\tby\n",
            "O\t\tO\t\t\t\tthe\n",
            "O\t\tO\t\t\t\tforeign\n",
            "O\t\tO\t\t\t\tministers\n",
            "O\t\tO\t\t\t\tof\n",
            "B-geo\t\tB-gpe\t\t\t\tEgypt\n",
            "O\t\tO\t\t\t\tand\n",
            "B-gpe\t\tB-gpe\t\t\t\tJordan\n",
            "O\t\tO\t\t\t\twill\n",
            "O\t\tO\t\t\t\ttake\n",
            "O\t\tO\t\t\t\tplace\n",
            "B-tim\t\tB-tim\t\t\t\tJuly\n",
            "I-tim\t\tI-tim\t\t\t\t25\n",
            "O\t\tO\t\t\t\t,\n",
            "O\t\tO\t\t\t\tnot\n",
            "O\t\tO\t\t\t\tthis\n",
            "O\t\tO\t\t\t\tweek\n",
            "O\t\tO\t\t\t\tas\n",
            "O\t\tO\t\t\t\tpreviously\n",
            "O\t\tO\t\t\t\tplanned\n",
            "O\t\tO\t\t\t\t.\n",
            "<end>\t\t<end>\t\t\t\t<end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdqHslGcyE6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}