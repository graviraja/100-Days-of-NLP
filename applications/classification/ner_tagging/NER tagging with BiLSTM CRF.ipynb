{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER tagging with BiLSTM-CRF.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2haF4Hn2kRNz",
        "vIFVl-O_kUJb",
        "RBVQHwTVk88N",
        "wwiiGscn29-V",
        "1Fpc9vWq3EY3",
        "zv1kwAoG3IzE",
        "TeoX6uxx3MVe",
        "5urAtI4W3OUf",
        "TIXBCe7S3c3y"
      ],
      "authorship_tag": "ABX9TyPxpae660yk6Cq17G9X23lU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fclassification/applications/classification/ner_tagging/NER%20tagging%20with%20BiLSTM%20CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeK9dZJmkDQg",
        "colab_type": "text"
      },
      "source": [
        "### NER Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5jkJpQvdgjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "221b6ca5-7ee5-4a27-9358-3f26b2d7119b"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5eEi8pCZYYu",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d6263a9e-5ce5-43f9-c51d-189b6c95eef5"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cff059d2-c1c0-4c00-a008-31cb943a3d5e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cff059d2-c1c0-4c00-a008-31cb943a3d5e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ravirajag\",\"key\":\"7c9b32c3baf1bd5e404db6e4e281fc5c\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBOvFvrBdm1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKDfern7eAi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2cf3331a-1496-467f-9c9e-5581d7145eab"
      },
      "source": [
        "!kaggle datasets download -d abhinavwalia95/entity-annotated-corpus"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading entity-annotated-corpus.zip to /content\n",
            " 34% 9.00M/26.4M [00:00<00:00, 18.6MB/s]\n",
            "100% 26.4M/26.4M [00:00<00:00, 45.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1LvqrEIeFvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9586f018-c69e-4c95-f691-3bf8b414c646"
      },
      "source": [
        "!unzip entity-annotated-corpus.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  entity-annotated-corpus.zip\n",
            "  inflating: ner.csv                 \n",
            "  inflating: ner_dataset.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuSoeUl3kFz2",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD_gnl5YQHEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "093caa9a-dece-4ef4-ca33-54256b0251e7"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NemuvQdVpGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "09a9d872-25d4-4a0f-c13d-0b2bb575d1f4"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNeeukPGkLSC",
        "colab_type": "text"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM1ADdqCeRcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datafile = 'ner_dataset.csv'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXIfU9fBfB6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(datafile, encoding=\"latin1\", error_bad_lines=False)\n",
        "df = df.fillna(method='ffill')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T1WOTYVfRLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "9518c01f-2b17-4b6c-fd61-b153e607bd11"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAzzVjPqf7Lb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2724d610-2cc3-486f-db33-91e68542bd20"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1048575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c16vzijfkwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "4a352a3b-1bdb-421d-b4de-366a076f3b38"
      },
      "source": [
        "tags = list(df.Tag.unique())\n",
        "tags"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-geo',\n",
              " 'B-gpe',\n",
              " 'B-per',\n",
              " 'I-geo',\n",
              " 'B-org',\n",
              " 'I-org',\n",
              " 'B-tim',\n",
              " 'B-art',\n",
              " 'I-art',\n",
              " 'I-per',\n",
              " 'I-gpe',\n",
              " 'I-tim',\n",
              " 'B-nat',\n",
              " 'B-eve',\n",
              " 'I-eve',\n",
              " 'I-nat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eKeAR8DftPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "89901e22-d645-40b5-c017-85a90a38ec37"
      },
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "sns.countplot(df.Tag.values)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fc50e6da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPDMLtKdhFrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47d5cff9-dec6-4f15-b762-6416947ae9a1"
      },
      "source": [
        "num_tags = len(tags)\n",
        "num_tags"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2haF4Hn2kRNz",
        "colab_type": "text"
      },
      "source": [
        "### Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSmI25jJhjLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agg_func = lambda s: [(w, t) for w, p, t in zip(s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist())]\n",
        "group = df.groupby(\"Sentence #\").apply(agg_func)\n",
        "lines = [s for s in group]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RknB-LoUiATn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "c66bc79c-76d8-4c1f-b052-1cb26eee77bb"
      },
      "source": [
        "lines[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Thousands', 'O'),\n",
              " ('of', 'O'),\n",
              " ('demonstrators', 'O'),\n",
              " ('have', 'O'),\n",
              " ('marched', 'O'),\n",
              " ('through', 'O'),\n",
              " ('London', 'B-geo'),\n",
              " ('to', 'O'),\n",
              " ('protest', 'O'),\n",
              " ('the', 'O'),\n",
              " ('war', 'O'),\n",
              " ('in', 'O'),\n",
              " ('Iraq', 'B-geo'),\n",
              " ('and', 'O'),\n",
              " ('demand', 'O'),\n",
              " ('the', 'O'),\n",
              " ('withdrawal', 'O'),\n",
              " ('of', 'O'),\n",
              " ('British', 'B-gpe'),\n",
              " ('troops', 'O'),\n",
              " ('from', 'O'),\n",
              " ('that', 'O'),\n",
              " ('country', 'O'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLJvFI3yqgi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [['<START>'] + [tokens[0] for tokens in line] + ['<END'] for line in lines]\n",
        "tags = [['<START>'] + [tokens[1] for tokens in line] + ['<END'] for line in lines]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A0xItc3iFhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5599f9cf-9a9b-4e0a-a816-8c91de397929"
      },
      "source": [
        "len(sentences), len(tags)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47959, 47959)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH_xnhJFkj1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "717ab1dd-ae84-4480-f619-e438d07413d1"
      },
      "source": [
        "sen_lengths = [len(sent) for sent in sentences]\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.countplot(sen_lengths)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fae99fc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5HlzOzGmEDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59b94dc5-4965-4f07-8bae-f9071219569f"
      },
      "source": [
        "train_sentences, valid_sentences, train_tags, valid_tags = train_test_split(sentences, tags, test_size=0.2, random_state=42)\n",
        "valid_sentences, test_sentences, valid_tags, test_tags = train_test_split(valid_sentences, valid_tags, test_size=0.5, random_state=42)\n",
        "len(train_sentences), len(valid_sentences), len(test_sentences)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38367, 4796, 4796)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFVl-O_kUJb",
        "colab_type": "text"
      },
      "source": [
        "### Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9eJdmdhoamw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocab:\n",
        "    def __init__(self, word2id, id2word):\n",
        "        self.UNK = '<UNK>'\n",
        "        self.PAD = '<PAD>'\n",
        "        self.START = '<START>'\n",
        "        self.END = '<END>'\n",
        "        self.__word2id = word2id\n",
        "        self.__id2word = id2word\n",
        "\n",
        "    def get_word2id(self):\n",
        "        return self.__word2id\n",
        "\n",
        "    def get_id2word(self):\n",
        "        return self.__id2word\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        if self.UNK in self.__word2id:\n",
        "            return self.__word2id.get(item, self.__word2id[self.UNK])\n",
        "        return self.__word2id[item]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.__word2id)\n",
        "\n",
        "    def id2word(self, idx):\n",
        "        return self.__id2word[idx]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YlwfEdHocqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(data, freq_cutoff=5, is_tags=False):\n",
        "    word_counts = Counter(chain(*data))\n",
        "    valid_words = [w for w, d in word_counts.items() if d >= freq_cutoff]\n",
        "    valid_words = sorted(valid_words, key=lambda x: word_counts[x], reverse=True)\n",
        "    valid_words += ['<PAD>']\n",
        "    word2id = {w: idx for idx, w in enumerate(valid_words)}\n",
        "    if not is_tags:\n",
        "        word2id['<UNK>'] = len(word2id)\n",
        "        valid_words += ['<UNK>']\n",
        "    return Vocab(word2id=word2id, id2word=valid_words)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzicTNXdj8Rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_vocab = build_vocab(train_sentences)\n",
        "tags_vocab = build_vocab(train_tags)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBVQHwTVk88N",
        "colab_type": "text"
      },
      "source": [
        "### NER Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3RhXjbdk_Jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEN_LEN = 50"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Jc4l5NVwnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NERDataset(data.Dataset):\n",
        "    def __init__(self, sentences, tags, max_len):\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        sentence = self.sentences[item]\n",
        "        tag = self.tags[item]\n",
        "        tokens, tags = [], []\n",
        "\n",
        "        for word, t in zip(sentence, tag):\n",
        "            tokens.append(words_vocab[word])\n",
        "            tags.append(tags_vocab[t])\n",
        "\n",
        "        return torch.LongTensor(tokens), torch.LongTensor(tags)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2McipX1Nl-8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = NERDataset(train_sentences, train_tags, MAX_SEN_LEN)\n",
        "valid_dataset = NERDataset(valid_sentences, valid_tags, MAX_SEN_LEN)\n",
        "test_dataset = NERDataset(test_sentences, test_tags, MAX_SEN_LEN)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1cFfg0IqFE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "b4f0d568-6d71-41ae-c645-d58d02e58466"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   1,  150,  235,   11,   36,   72,   49, 3318,    8, 1977, 4171,  166,\n",
              "         9619, 9619, 7832,    4,  199,    7, 1385, 9619,   67, 1103,    3,    2]),\n",
              " tensor([ 1,  3, 10,  0,  0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwiiGscn29-V",
        "colab_type": "text"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGPqxgEboFV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpHqwpKNqtcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_fn(data):\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "    sentences, tags = zip(*data)\n",
        "\n",
        "    # Merge questions (from tuple of 1D tensor to 2D tensor).\n",
        "    sent_lengths = [len(sent) for sent in sentences]\n",
        "    inputs = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
        "    labels = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
        "    \n",
        "    for i, (sent, lab) in enumerate(zip(sentences, tags)):\n",
        "        end = sent_lengths[i]\n",
        "        inputs[i, :end] = sent[:end]\n",
        "        labels[i, :end] = lab[:end]\n",
        "\n",
        "    return inputs, labels, sent_lengths\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohUjd1c_rwqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_loader = data.DataLoader(train_dataset, BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_data_loader = data.DataLoader(valid_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_data_loader = data.DataLoader(test_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQHLq_P4n3AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = next(iter(train_data_loader))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlQV_LyNs9PT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c69924f8-0205-4541-e66f-992a414f4088"
      },
      "source": [
        "sample[0].shape, sample[1].shape, len(sample[2])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 59]), torch.Size([128, 59]), 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q08pzQGp3Ami",
        "colab_type": "text"
      },
      "source": [
        "### BiLSTM-CRF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFzphEAGTxad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTMCRF(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, tag_vocab_size, sent_pad_token, tag_start_token, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.sent_pad_token = sent_pad_token\n",
        "        self.tag_start_token = tag_start_token\n",
        "        self.tag_vocab_size = tag_vocab_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim,\n",
        "            hid_dim,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.emission = nn.Linear(hid_dim * 2, tag_vocab_size)\n",
        "        self.transition = nn.Parameter(torch.rand(tag_vocab_size, tag_vocab_size))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, sentences, lengths, tags):\n",
        "        # sentences => [batch_size, seq_len]\n",
        "        # lengths => [batch_size]\n",
        "        # tags => [batch_size, seq_len]\n",
        "\n",
        "        mask = (sentences != self.sent_pad_token).to(device)\n",
        "        # mask => [batch_size, seq_len]\n",
        "\n",
        "        embed = self.embedding(sentences)\n",
        "        embed = self.dropout(embed)\n",
        "        # embed => [batch_size, seq_len, emb_dim]\n",
        "\n",
        "        packed_inp = nn.utils.rnn.pack_padded_sequence(embed, lengths, batch_first=True)\n",
        "        packed_output, _ = self.lstm(packed_inp)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
        "        # outputs => [batch_size, seq_len, hid_dim * 2]\n",
        "\n",
        "        combined = torch.cat((outputs[:, :, :self.hid_dim], outputs[:, :, self.hid_dim:]), dim=-1)\n",
        "        combined = self.dropout(combined)\n",
        "        # combined => [batch_size, seq_len, hid_dim * 2]\n",
        "\n",
        "        emission_scores = self.emission(combined)\n",
        "        # emission_scores => [batch_size, seq_len, tag_size]\n",
        "\n",
        "        loss = self.vitebri_loss(tags, mask, emission_scores)\n",
        "        # loss => [batch_size]\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def vitebri_loss(self, tags, mask, emit_scores):\n",
        "        # tags => [batch_size, seq_len]\n",
        "        # mask => [batch_size, seq_len]\n",
        "        # emit_scores => [batch_size, seq_len, tag_size]\n",
        "\n",
        "        batch_size, sent_len = tags.shape\n",
        "\n",
        "        # calculate the ground truth score\n",
        "        score = torch.gather(emit_scores, 2, tags.unsqueeze(2)).squeeze(2)\n",
        "        # emission scores of actual tags\n",
        "        # score => [batch_size, seq_len]\n",
        "\n",
        "        # add the transition scores to the emission scores\n",
        "        # ignore the start token tag score\n",
        "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
        "\n",
        "        # consider only the scores of actual tokens not the padded\n",
        "        gold_scores = (score * mask.type(torch.float)).sum(dim=1)\n",
        "        # gold_scores => [batch_size]\n",
        "\n",
        "        # calculate the scores of the partition (Z)\n",
        "        # tensor to hold the accumulated sequence scores at each time step\n",
        "        # at the inital time step score will be on dim=0\n",
        "        scores_upto_t = emit_scores[:, 0].unsqueeze(1)\n",
        "        # scores_upto_t => [batch_size, 1, tag_size]\n",
        "\n",
        "        for i in range(1, sent_len):\n",
        "            # get the current batch_size\n",
        "            batch_t = mask[:, i].sum()\n",
        "\n",
        "            # get the accumulated scores till now (only the current batch size)\n",
        "            scores_unpad = scores_upto_t[:batch_t]\n",
        "            # scores_unpad => [batch_t, 1, tag_size]\n",
        "\n",
        "            # add the transition scores for this time step\n",
        "            scores_with_trans = emit_scores[:batch_t, i].unsqueeze(1) + self.transition\n",
        "            # scores_with_trans => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            # add to the accumulation\n",
        "            sum_scores = scores_unpad.transpose(1, 2) + scores_with_trans\n",
        "            # sum_scores => [batch_t, tag_size, tag_size]\n",
        "            \n",
        "            # apply the following to overcome the overflow problems\n",
        "            # since the exp(some_big_number) will cause issues \n",
        "            # log( exp(z_k)) = max(z) + log( exp(z_k - max(z)))\n",
        "            # log( exp(z_k)) = log( exp(z_k - c + c))\n",
        "            #                 = log( exp(z_k - c) * exp(c))\n",
        "            #                 = log( exp(z_k - c)) + log(exp(c))\n",
        "            #                 = log( exp(z_k - c)) + c\n",
        "            # by taking c as max(z)\n",
        "            # log( exp(z_k)) = max(z) + log( exp(z_k - max(z))) [log_sum_exp]\n",
        "            # get the maximum score of the current time step\n",
        "            max_t = sum_scores.max(dim=1)[0].unsqueeze(1)\n",
        "            # max_t => [batch_t, 1, tag_size]\n",
        "\n",
        "            sum_scores = sum_scores - max_t\n",
        "            # sum_scores => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            scores_t = max_t + torch.logsumexp(sum_scores, dim=1).unsqueeze(1)\n",
        "            # scores_t => [batch_t, 1, tag_size]\n",
        "\n",
        "            # update the accumulation scores\n",
        "            scores_upto_t = torch.cat((scores_t, scores_upto_t[batch_t:]), dim=0)\n",
        "            # scores_upto_t => [batch_size, 1, tag_size]\n",
        "        \n",
        "        final_scores = scores_upto_t.squeeze(1)\n",
        "        # final_scores => [batch_size, tag_size]\n",
        "\n",
        "        max_final_scores = final_scores.max(dim=-1)[0]\n",
        "        # max_final_scores => [batch_size]\n",
        "\n",
        "        predicted_scores = max_final_scores + torch.logsumexp(final_scores - max_final_scores.unsqueeze(1), dim=1)\n",
        "        # predicted_scores => [batch_size]\n",
        "\n",
        "        vitebri_loss = predicted_scores - gold_scores\n",
        "        # vitebri_loss => [batch_size]\n",
        "\n",
        "        return vitebri_loss\n",
        "    \n",
        "    def predict(self, sentences, lengths):\n",
        "        # sentences => [batch_size, seq_len]\n",
        "        # lengths => [batch_size]\n",
        "\n",
        "        batch_size = sentences.size(0)\n",
        "        mask = (sentences != self.sent_pad_token).to(device)\n",
        "        # mask => [batch_size, seq_len]\n",
        "\n",
        "        embed = self.embedding(sentences)\n",
        "        embed = self.dropout(embed)\n",
        "        # embed => [batch_size, seq_len, emb_dim]\n",
        "\n",
        "        packed_inp = nn.utils.rnn.pack_padded_sequence(embed, lengths, batch_first=True)\n",
        "        packed_output, _ = self.lstm(packed_inp)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
        "        # outputs => [batch_size, seq_len, hid_dim * 2]\n",
        "\n",
        "        combined = torch.cat((outputs[:, :, :self.hid_dim], outputs[:, :, self.hid_dim:]), dim=-1)\n",
        "        combined = self.dropout(combined)\n",
        "        # combined => [batch_size, seq_len, hid_dim * 2]\n",
        "\n",
        "        emission_scores = self.emission(combined)\n",
        "        # emission_scores => [batch_size, seq_len, tag_size]\n",
        "\n",
        "        # to store the tags predicted at each time step\n",
        "        # since at the begining every tag is start tag create the list with start tags\n",
        "        tags = [[[self.tag_start_token] for _ in range(self.tag_vocab_size)]] * batch_size\n",
        "        # tags => [batch_size, tag_size, 1]\n",
        "\n",
        "        scores_upto_t = emission_scores[:, 0].unsqueeze(1)\n",
        "        # scores_upto_t => [batch_size, 1, tag_size]\n",
        "\n",
        "        for i in range(1, max(lengths)):\n",
        "            # get the current batch_size\n",
        "            batch_t = mask[:, i].sum()\n",
        "\n",
        "            # get the accumulated scores till now (only the current batch size)\n",
        "            scores_unpad = scores_upto_t[:batch_t]\n",
        "            # scores_unpad => [batch_t, 1, tag_size]\n",
        "\n",
        "            # add the transition scores for this time step\n",
        "            scores_with_trans = emission_scores[:batch_t, i].unsqueeze(1) + self.transition\n",
        "            # scores_with_trans => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            # add to the accumulation\n",
        "            sum_scores = scores_unpad.transpose(1, 2) + scores_with_trans\n",
        "            # sum_scores => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            max_scores_t, max_ids_t = torch.max(sum_scores, dim=1)\n",
        "            max_ids_t = max_ids_t.tolist()\n",
        "            # max_scores_t => [batch_t, tag_size]\n",
        "            # max_ids_t => [batch_t, tag_size]\n",
        "\n",
        "            # add the current time step predicted tags \n",
        "            tags[:batch_t] = [[tags[b][k] + [j] for j, k in enumerate(max_ids_t[b])] for b in range(batch_t)]\n",
        "            \n",
        "            # update the accumulation scores\n",
        "            scores_upto_t = torch.cat((max_scores_t.unsqueeze(1), scores_upto_t[batch_t:]), dim=0)\n",
        "            # scores_upto_t => [batch_size, tag_size]\n",
        "\n",
        "        scores = scores_upto_t.squeeze(1)\n",
        "        # scores => [batch_size, tag_size]\n",
        "\n",
        "        _, max_ids = torch.max(scores, dim=1)\n",
        "        max_ids = max_ids.tolist()\n",
        "        # max_ids => [batch_size]\n",
        "\n",
        "        # tags => [batch_size, tag_size, seq_len]\n",
        "        tags = [tags[b][k] for b, k in enumerate(max_ids)]\n",
        "        # tags => [batch_size, seq_len]\n",
        "\n",
        "        return tags\n",
        "\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEY0Z8WMVmZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "15dde0dd-ebf2-45c1-b0e6-89c5559adb3b"
      },
      "source": [
        "vocab_size = len(words_vocab)\n",
        "sent_pad_token = words_vocab[words_vocab.PAD]\n",
        "tag_start_token = tags_vocab[tags_vocab.START]\n",
        "emb_dim = 50\n",
        "hid_dim = 100\n",
        "tag_vocab_size = len(tags_vocab)\n",
        "model = BiLSTMCRF(vocab_size, emb_dim, hid_dim, tag_vocab_size, sent_pad_token, tag_start_token)\n",
        "model.to(device)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTMCRF(\n",
              "  (embedding): Embedding(9620, 50, padding_idx=0)\n",
              "  (lstm): LSTM(50, 100, batch_first=True, bidirectional=True)\n",
              "  (emission): Linear(in_features=200, out_features=21, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuu7YjwQt3-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f7873f6-1315-4d19-af84-6b26f853449d"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 607,262 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fpc9vWq3EY3",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKhNhP5_uFsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv1kwAoG3IzE",
        "colab_type": "text"
      },
      "source": [
        "### Training Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJQZHAmGuP-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, clip):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    total_sentences = 0\n",
        "\n",
        "    for batch in iterator:\n",
        "        sentences = batch[0].to(device)\n",
        "        tags = batch[1].to(device)\n",
        "        seq_lengths = batch[2]\n",
        "        # sentences => [batch_size, seq_len]\n",
        "        # tags => [batch_size, seq_len]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_loss = model(sentences, seq_lengths, tags)\n",
        "        # batch_loss => [batch_size]\n",
        "\n",
        "        loss = batch_loss.mean()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += batch_loss.sum().item()\n",
        "        total_sentences += len(sentences)\n",
        "\n",
        "    return epoch_loss / total_sentences\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeoX6uxx3MVe",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK-UR_62uS0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    total_sentences = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            sentences = batch[0].to(device)\n",
        "            tags = batch[1].to(device)\n",
        "            seq_lengths = batch[2]\n",
        "            # sentences => [batch_size, seq_len]\n",
        "            # tags => [batch_size, seq_len]\n",
        "\n",
        "            batch_loss = model(sentences, seq_lengths, tags)\n",
        "            # batch_loss => [batch_size]\n",
        "\n",
        "            loss = batch_loss.mean()\n",
        "\n",
        "            epoch_loss += batch_loss.sum().item()\n",
        "            total_sentences += len(sentences)\n",
        "        \n",
        "    return epoch_loss / total_sentences\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5urAtI4W3OUf",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8_N8-U6uUtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL5kQHBluWkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "d5f2502d-1ab2-4b81-af93-1e4163e2fb7f"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 2\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_data_loader, optimizer, CLIP)\n",
        "    valid_loss = evaluate(model, valid_data_loader)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 15.869 | Val. Loss: 2.219\n",
            "Epoch: 02 | Epoch Time: 0m 17s\n",
            "\tTrain Loss: 2.285 | Val. Loss: 1.898\n",
            "Epoch: 03 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 1.951 | Val. Loss: 1.775\n",
            "Epoch: 04 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 1.796 | Val. Loss: 1.757\n",
            "Epoch: 05 | Epoch Time: 0m 17s\n",
            "\tTrain Loss: 1.703 | Val. Loss: 1.684\n",
            "Epoch: 06 | Epoch Time: 0m 17s\n",
            "\tTrain Loss: 1.639 | Val. Loss: 1.681\n",
            "Epoch: 07 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 1.570 | Val. Loss: 1.686\n",
            "Epoch: 08 | Epoch Time: 0m 17s\n",
            "\tTrain Loss: 1.537 | Val. Loss: 1.657\n",
            "Epoch: 09 | Epoch Time: 0m 17s\n",
            "\tTrain Loss: 1.499 | Val. Loss: 1.666\n",
            "Epoch: 10 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 1.476 | Val. Loss: 1.667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIXBCe7S3c3y",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqDAWdc8vVAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5becb514-f2e0-42bc-d5f7-49648e3ecdb7"
      },
      "source": [
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKC73CrN3Ycb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0a60ec1-dfb8-4db6-d3f1-cfaaf3177429"
      },
      "source": [
        "test_loss = evaluate(model, test_data_loader)\n",
        "print(f'Test Loss: {test_loss:.3f}')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEH5FeEBt4BY",
        "colab_type": "text"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQOhx3g3lmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(sentence):\n",
        "    if isinstance(sentence, str):\n",
        "        tokens = [words_vocab[words_vocab.START]] + sentence.split() + [words_vocab[words_vocab.END]]\n",
        "    else:\n",
        "        tokens = sentence\n",
        "    \n",
        "    # numericalize\n",
        "    token_ids = [words_vocab[tok] for tok in tokens]\n",
        "    \n",
        "    # seq length\n",
        "    sent_length = [len(token_ids)]\n",
        "\n",
        "    # create tensors\n",
        "    sent_tensor = torch.LongTensor(token_ids).to(device)\n",
        "    sent_tensor = sent_tensor.unsqueeze(0)\n",
        "    # sent_tensor => [1, seq_len]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model.predict(sent_tensor, sent_length)\n",
        "    \n",
        "    predictions = predictions[0]\n",
        "    predicted_tags = []\n",
        "    for i in predictions:\n",
        "        predicted_tags.append(tags_vocab.id2word(i))\n",
        "    \n",
        "    return tokens, predicted_tags\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUrgvPn1vj0W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "9a780a0c-f164-4bff-c9c4-9f41d581f172"
      },
      "source": [
        "sentence = test_sentences[0]\n",
        "actual_tags = test_tags[0]\n",
        "tokens, predicted_tag_ids = inference(sentence)\n",
        "\n",
        "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
        "for token, pred_tag, actual_tag in zip(tokens, predicted_tag_ids, actual_tags):\n",
        "    correct = '' if pred_tag == actual_tag else ''\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
            "\n",
            "<START>\t\t<START>\t\t\t\t<START>\n",
            "O\t\tO\t\t\t\tThe\n",
            "O\t\tO\t\t\t\toffice\n",
            "O\t\tO\t\t\t\tof\n",
            "O\t\tO\t\t\t\tthe\n",
            "B-gpe\t\tB-gpe\t\t\t\tIsraeli\n",
            "O\t\tO\t\t\t\tprime\n",
            "O\t\tO\t\t\t\tminister\n",
            "O\t\tO\t\t\t\tsays\n",
            "O\t\tO\t\t\t\ta\n",
            "O\t\tO\t\t\t\tvisit\n",
            "O\t\tO\t\t\t\tto\n",
            "B-geo\t\tB-geo\t\t\t\tIsrael\n",
            "O\t\tO\t\t\t\tby\n",
            "O\t\tO\t\t\t\tthe\n",
            "O\t\tO\t\t\t\tforeign\n",
            "O\t\tO\t\t\t\tministers\n",
            "O\t\tO\t\t\t\tof\n",
            "B-geo\t\tB-gpe\t\t\t\tEgypt\n",
            "O\t\tO\t\t\t\tand\n",
            "B-gpe\t\tB-gpe\t\t\t\tJordan\n",
            "O\t\tO\t\t\t\twill\n",
            "O\t\tO\t\t\t\ttake\n",
            "O\t\tO\t\t\t\tplace\n",
            "B-tim\t\tB-tim\t\t\t\tJuly\n",
            "I-tim\t\tI-tim\t\t\t\t25\n",
            "O\t\tO\t\t\t\t,\n",
            "O\t\tO\t\t\t\tnot\n",
            "O\t\tO\t\t\t\tthis\n",
            "O\t\tO\t\t\t\tweek\n",
            "O\t\tO\t\t\t\tas\n",
            "O\t\tO\t\t\t\tpreviously\n",
            "O\t\tO\t\t\t\tplanned\n",
            "O\t\tO\t\t\t\t.\n",
            "<END\t\t<END\t\t\t\t<END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UDJLIFLzlsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}