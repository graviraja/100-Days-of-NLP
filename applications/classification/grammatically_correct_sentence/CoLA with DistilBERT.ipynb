{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoLA with DistilBERT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmDZOKqlsxgp4yIsz+nJw7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e1ef918514b94bbd8828a48e43d387ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4145406ccce941ea920caa10bd0b34eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31524e875c8f4cc5aa4273fbb282f086",
              "IPY_MODEL_c009161d6f484e5faffef66d578f0eb0"
            ]
          }
        },
        "4145406ccce941ea920caa10bd0b34eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31524e875c8f4cc5aa4273fbb282f086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3ff1b0ffc9f5403481b86df6b2c60125",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0fe0817ada54269ab6a3e93214b6cde"
          }
        },
        "c009161d6f484e5faffef66d578f0eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e28992ddfd974387a4777b97b18a1749",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 391kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87d2e814fc0c45ae90bb4da94e5b029d"
          }
        },
        "3ff1b0ffc9f5403481b86df6b2c60125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0fe0817ada54269ab6a3e93214b6cde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e28992ddfd974387a4777b97b18a1749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87d2e814fc0c45ae90bb4da94e5b029d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd509f2084fa4142b496243036ea7ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad969fdee59a4cd890e4db4ca91e6251",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d7dca0957b674c3b903492b2e23c9372",
              "IPY_MODEL_b081a397aef747c0bd20dacf6b85962f"
            ]
          }
        },
        "ad969fdee59a4cd890e4db4ca91e6251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d7dca0957b674c3b903492b2e23c9372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ef5e9b9d33c14ff5b43895c824955bcf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f32349e4205f4453801c00bb54516cd0"
          }
        },
        "b081a397aef747c0bd20dacf6b85962f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15959302203f40b98a01dc87972c8e85",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:06&lt;00:00, 70.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d536fb716498440ba8b809a57fac1ad3"
          }
        },
        "ef5e9b9d33c14ff5b43895c824955bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f32349e4205f4453801c00bb54516cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15959302203f40b98a01dc87972c8e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d536fb716498440ba8b809a57fac1ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0dc0f7a3f0214c55b74d26a3bf36741e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_98f2f6bb0c96442186442dfd84c80d60",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc3abb818bb94be48b4493b063c4de8a",
              "IPY_MODEL_3fc16b08566e49a59372f975f6cec026"
            ]
          }
        },
        "98f2f6bb0c96442186442dfd84c80d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc3abb818bb94be48b4493b063c4de8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e689a5a85e354d3aa20a1600e19bdd9f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e47ef712fba54a38a52afd8b9ad8f945"
          }
        },
        "3fc16b08566e49a59372f975f6cec026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a16c0c5750446ad90b494a12ebb9091",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:05&lt;00:00, 76.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44455a3b72b047ddb590428b8c1fb7d1"
          }
        },
        "e689a5a85e354d3aa20a1600e19bdd9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e47ef712fba54a38a52afd8b9ad8f945": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a16c0c5750446ad90b494a12ebb9091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44455a3b72b047ddb590428b8c1fb7d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fclassification/applications/classification/grammatically_correct_sentence/CoLA%20with%20DistilBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eGUMKcQnspb",
        "colab_type": "text"
      },
      "source": [
        "### Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_FZz-Xw7eTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "outputId": "dc2dd8ee-981b-4982-b860-e64868a110f0"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 4.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 25.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=130ad7362244948ca6686c995d3e1f3fa94918b6868260757613c065bb128257\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=e4acb0340e7dde2ae15737f894e369e455ecf2c496c0768682de815594bffc06\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kES7eFgMnvHt",
        "colab_type": "text"
      },
      "source": [
        "### CoLA (Corpus of Linguistic Acceptability) Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8mPUkHcSLp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "53fffcae-e9ca-44b0-b6a4-065893b6d378"
      },
      "source": [
        "import os\n",
        "import wget\n",
        "\n",
        "print('Downloading dataset')\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJlrGp7pSsmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "0359c47f-ad64-4027-bf90-da6643b700ff"
      },
      "source": [
        "if not os.path.exists('./cola_public'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjHKbe82WlXz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "688c3a0e-2fc0-48b5-946d-2ea20682fc5c"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cola_public  cola_public_1.1.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP02ySzuUGGF",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUNQnti570qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Z6NdulS9lJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJND9cluTJ60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = \"cola_public/raw/in_domain_train.tsv\"\n",
        "test_file = \"cola_public/raw/in_domain_dev.tsv\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYdbhhMIrCnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(train_file, sep='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "df_valid = pd.read_csv(test_file, sep='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCIo68BNUCmu",
        "colab_type": "text"
      },
      "source": [
        "### Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8A8V7IfTTUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "5e0e0bc1-12d8-462f-d262-9189f74b7ef5"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our friends won't buy this analysis, let alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization and I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization or I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The more we study verbs, the crazier they get.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Day by day the facts are getting murkier.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentence_source  ...                                           sentence\n",
              "0            gj04  ...  Our friends won't buy this analysis, let alone...\n",
              "1            gj04  ...  One more pseudo generalization and I'm giving up.\n",
              "2            gj04  ...   One more pseudo generalization or I'm giving up.\n",
              "3            gj04  ...     The more we study verbs, the crazier they get.\n",
              "4            gj04  ...          Day by day the facts are getting murkier.\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6khq5eIiUyr7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "f3c0de40-9777-4699-eb2e-9d4731aadb78"
      },
      "source": [
        "df_train = df_train.drop(columns=['sentence_source', 'label_notes'])\n",
        "df_train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our friends won't buy this analysis, let alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>One more pseudo generalization and I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>One more pseudo generalization or I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>The more we study verbs, the crazier they get.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Day by day the facts are getting murkier.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                           sentence\n",
              "0      1  Our friends won't buy this analysis, let alone...\n",
              "1      1  One more pseudo generalization and I'm giving up.\n",
              "2      1   One more pseudo generalization or I'm giving up.\n",
              "3      1     The more we study verbs, the crazier they get.\n",
              "4      1          Day by day the facts are getting murkier."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1USvoRZU_A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_valid = df_valid.drop(columns=['sentence_source', 'label_notes'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-0ZnQVvUmXE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "87cad693-4736-4ab6-8f3e-52bc9338a1a3"
      },
      "source": [
        "df_train.shape, df_valid.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8551, 2), (527, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqCh8H-QYfEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "47de4a2e-ab62-4761-fd66-3e5d9c60e25f"
      },
      "source": [
        "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
        "df_train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Angela characterized Shelly as a lifesaver.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>They're not finding it a stress being in the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Paul exhaled on Mary.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>I ordered if John drink his beer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Press the stamp against the pad completely.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                           sentence\n",
              "0      1        Angela characterized Shelly as a lifesaver.\n",
              "1      1  They're not finding it a stress being in the s...\n",
              "2      0                              Paul exhaled on Mary.\n",
              "3      0                  I ordered if John drink his beer.\n",
              "4      1        Press the stamp against the pad completely."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG9CIfyCTgIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "ab5e5e2a-0792-4e08-d83b-6938c69367c1"
      },
      "source": [
        "sns.countplot(df_train['label'].values)\n",
        "plt.xlabel(\"Training Data Distribution\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Training Data Distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUdklEQVR4nO3dfbRldX3f8fcHBmJSBQaZTglDO0SnurCJQKeAGl1GUp6iDsv6gCstI6WduErUtDYGXW2hGLNMYktEDYZVRgdLQSRVJsZKJ4gxRnm4CEEepDOFEGYKzIQBFIwkQ7794/xuPAz33t8Zcs+9d7jv11pnnb2/+7f3/s5Zs87n7n322SdVhSRJM9lnvhuQJC18hoUkqcuwkCR1GRaSpC7DQpLUtWS+GxiHQw45pFauXDnfbUjSXuXmm2/+86paNtWy52RYrFy5komJifluQ5L2Kknum26Zp6EkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSusYaFkkOSnJVku8kuSvJK5IcnGRTks3teWkbmyQXJtmS5LYkxwxtZ20bvznJ2nH2LEl6pnEfWXwU+HJVvRR4OXAXcA5wbVWtAq5t8wCnAKvaYx1wEUCSg4FzgeOAY4FzJwNGkjQ3xhYWSQ4EXgNcAlBVf1lVjwJrgA1t2AbgtDa9Bri0Bq4HDkpyKHASsKmqdlbVI8Am4ORx9S1JeqZxfoP7CGAH8KkkLwduBt4DLK+qB9qYB4Hlbfow4P6h9be22nR1aVH6s/N/cr5b0AL09//Tt8e6/XGehloCHANcVFVHA0/ww1NOANTgZ/pm5af6kqxLMpFkYseOHbOxSUlSM86w2Apsraob2vxVDMLjoXZ6ifa8vS3fBhw+tP6KVpuu/jRVdXFVra6q1cuWTXkfLEnSszS2sKiqB4H7k7yklU4A7gQ2ApNXNK0Frm7TG4Ez2lVRxwOPtdNV1wAnJlnaPtg+sdUkSXNk3HedfRdwWZL9gXuAMxkE1JVJzgLuA97axn4JOBXYAny/jaWqdib5IHBTG3d+Ve0cc9+SpCFjDYuquhVYPcWiE6YYW8DZ02xnPbB+druTJI3Kb3BLkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lS11jDIsmfJvl2kluTTLTawUk2Jdncnpe2epJcmGRLktuSHDO0nbVt/OYka8fZsyTpmebiyOJnquqoqlrd5s8Brq2qVcC1bR7gFGBVe6wDLoJBuADnAscBxwLnTgaMJGluzMdpqDXAhja9AThtqH5pDVwPHJTkUOAkYFNV7ayqR4BNwMlz3bQkLWbjDosC/neSm5Osa7XlVfVAm34QWN6mDwPuH1p3a6tNV3+aJOuSTCSZ2LFjx2z+GyRp0Vsy5u3/dFVtS/J3gU1JvjO8sKoqSc3GjqrqYuBigNWrV8/KNiVJA2M9sqiqbe15O/B5Bp85PNROL9Get7fh24DDh1Zf0WrT1SVJc2RsYZHk7yR5weQ0cCJwO7ARmLyiaS1wdZveCJzRroo6Hnisna66BjgxydL2wfaJrSZJmiPjPA21HPh8ksn9/I+q+nKSm4Ark5wF3Ae8tY3/EnAqsAX4PnAmQFXtTPJB4KY27vyq2jnGviVJuxlbWFTVPcDLp6g/DJwwRb2As6fZ1npg/Wz3KEkajd/gliR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1jT0skuyb5JYkX2zzRyS5IcmWJJ9Nsn+r/0ib39KWrxzaxvtb/e4kJ427Z0nS083FkcV7gLuG5n8duKCqXgw8ApzV6mcBj7T6BW0cSY4ETgdeBpwM/HaSfeegb0lSM9awSLIC+Dngv7X5AK8DrmpDNgCntek1bZ62/IQ2fg1wRVU9WVX3AluAY8fZtyTp6cZ9ZPFbwPuAv27zLwQerapdbX4rcFibPgy4H6Atf6yN/5v6FOv8jSTrkkwkmdixY8ds/zskaVEbW1gkeT2wvapuHtc+hlXVxVW1uqpWL1u2bC52KUmLxpIxbvtVwBuTnAo8DzgA+ChwUJIl7ehhBbCtjd8GHA5sTbIEOBB4eKg+aXgdSdIcGNuRRVW9v6pWVNVKBh9Qf6Wqfh64DnhzG7YWuLpNb2zztOVfqapq9dPb1VJHAKuAG8fVtyTpmcZ5ZDGdXwGuSPKrwC3AJa1+CfCZJFuAnQwChqq6I8mVwJ3ALuDsqnpq7tuWpMVrTsKiqr4KfLVN38MUVzNV1Q+At0yz/oeAD42vQ0nSTPwGtySpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUNVJYJLl2lJok6blpxrvOJnke8GPAIUmWAmmLDmCKnzaVJD039W5R/gvALwE/DtzMD8Piu8DHx9iXJGkBmTEsquqjwEeTvKuqPjZHPUmSFpiRfvyoqj6W5JXAyuF1qurSMfUlSVpARgqLJJ8BXgTcCkz+pGkBhoUkLQKj/qzqauDIqqpxNiNJWphG/Z7F7cDfG2cjkqSFa9Qji0OAO5PcCDw5WayqN46lK0nSgjJqWJw3ziYkSQvbqFdD/eG4G5EkLVyjXg31PQZXPwHsD+wHPFFVB4yrMUnSwjHqkcULJqeTBFgDHD+upiRJC8se33W2Br4AnDTTuCTPS3Jjkj9JckeS/9zqRyS5IcmWJJ9Nsn+r/0ib39KWrxza1vtb/e4kM+5XkjT7Rj0N9aah2X0YfO/iB53VngReV1WPJ9kP+HqS/wX8O+CCqroiySeBs4CL2vMjVfXiJKcDvw68LcmRwOnAyxjco+oPkvzDqnpqqp1KkmbfqEcWbxh6nAR8j8GpqGm1I5DH2+x+7VHA64CrWn0DcFqbXtPmactPGDrldUVVPVlV9wJbgGNH7FuSNAtG/czizGez8ST7Mrhb7YuBTwD/F3i0qna1IVv54a3ODwPub/vbleQx4IWtfv3QZofXkSTNgVF//GhFks8n2d4ev5tkRW+9qnqqqo4CVjA4Gnjp37LfmXpcl2QiycSOHTvGtRtJWpRGPQ31KWAjg88Mfhz4vVYbSVU9ClwHvAI4KMnkEc0KYFub3gYcDtCWHwg8PFyfYp3hfVxcVauravWyZctGbU2SNIJRw2JZVX2qqna1x6eBGd+RkyxLclCb/lHgnwJ3MQiNN7dha4Gr2/TGNk9b/pV248KNwOntaqkjgFXAjSP2LUmaBaPe7uPhJP8cuLzNv53BX/0zORTY0D632Ae4sqq+mORO4IokvwrcAlzSxl8CfCbJFmAngyugqKo7klwJ3AnsAs72SihJmlujhsW/BD4GXMDgiqZvAO+YaYWqug04eor6PUxxNVNV/QB4yzTb+hDwoRF7lSTNslHD4nxgbVU9ApDkYOAjDEJEkvQcN+pnFj81GRQAVbWTKY4aJEnPTaOGxT5Jlk7OtCOLUY9KJEl7uVHf8P8L8M0kn2vzb8HPECRp0Rj1G9yXJplgcKsOgDdV1Z3ja0uStJCMfCqphYMBIUmL0B7folyStPgYFpKkLsNCktRlWEiSugwLSVKXX6ybxj/+5UvnuwUtQDf/5hnz3YI0LzyykCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqGltYJDk8yXVJ7kxyR5L3tPrBSTYl2dyel7Z6klyYZEuS25IcM7SttW385iRrx9WzJGlq4zyy2AW8t6qOBI4Hzk5yJHAOcG1VrQKubfMApwCr2mMdcBEMwgU4FzgOOBY4dzJgJElzY2xhUVUPVNW32vT3gLuAw4A1wIY2bANwWpteA1xaA9cDByU5FDgJ2FRVO6vqEWATcPK4+pYkPdOcfGaRZCVwNHADsLyqHmiLHgSWt+nDgPuHVtvaatPVd9/HuiQTSSZ27Ngxq/1L0mI39rBI8nzgd4FfqqrvDi+rqgJqNvZTVRdX1eqqWr1s2bLZ2KQkqRlrWCTZj0FQXFZV/7OVH2qnl2jP21t9G3D40OorWm26uiRpjozzaqgAlwB3VdV/HVq0EZi8omktcPVQ/Yx2VdTxwGPtdNU1wIlJlrYPtk9sNUnSHFkyxm2/CvgXwLeT3NpqHwA+DFyZ5CzgPuCtbdmXgFOBLcD3gTMBqmpnkg8CN7Vx51fVzjH2LUnazdjCoqq+DmSaxSdMMb6As6fZ1npg/ex1J0naE36DW5LUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUNbawSLI+yfYktw/VDk6yKcnm9ry01ZPkwiRbktyW5Jihdda28ZuTrB1Xv5Kk6Y3zyOLTwMm71c4Brq2qVcC1bR7gFGBVe6wDLoJBuADnAscBxwLnTgaMJGnujC0squprwM7dymuADW16A3DaUP3SGrgeOCjJocBJwKaq2llVjwCbeGYASZLGbK4/s1heVQ+06QeB5W36MOD+oXFbW226+jMkWZdkIsnEjh07ZrdrSVrk5u0D7qoqoGZxexdX1eqqWr1s2bLZ2qwkibkPi4fa6SXa8/ZW3wYcPjRuRatNV5ckzaG5DouNwOQVTWuBq4fqZ7Sroo4HHmunq64BTkyytH2wfWKrSZLm0JJxbTjJ5cBrgUOSbGVwVdOHgSuTnAXcB7y1Df8ScCqwBfg+cCZAVe1M8kHgpjbu/Kra/UNzSdKYjS0squrt0yw6YYqxBZw9zXbWA+tnsTVJ0h7yG9ySpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUtdeERZKTk9ydZEuSc+a7H0laTPaKsEiyL/AJ4BTgSODtSY6c364kafHYK8ICOBbYUlX3VNVfAlcAa+a5J0laNJbMdwMjOgy4f2h+K3Dc8IAk64B1bfbxJHfPUW+LwSHAn893EwtBPrJ2vlvQ0/l/c9K5mY2t/IPpFuwtYdFVVRcDF893H89FSSaqavV89yHtzv+bc2dvOQ21DTh8aH5Fq0mS5sDeEhY3AauSHJFkf+B0YOM89yRJi8ZecRqqqnYl+UXgGmBfYH1V3THPbS0mnt7TQuX/zTmSqprvHiRJC9zechpKkjSPDAtJUpdhoRl5mxUtREnWJ9me5Pb57mWxMCw0LW+zogXs08DJ893EYmJYaCbeZkULUlV9Ddg5330sJoaFZjLVbVYOm6deJM0jw0KS1GVYaCbeZkUSYFhoZt5mRRJgWGgGVbULmLzNyl3Ald5mRQtBksuBbwIvSbI1yVnz3dNznbf7kCR1eWQhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0JzLskLk9zaHg8m2TY0v39n3dVJLhxhH9+YpV5fm+SxJLe0u+9+LcnrR1zvlbO5ryTvTHLGs91nkjdO3jk4yaeTvHkP+/vAbvOz8hpr77BX/Kyqnluq6mHgKIAk5wGPV9VHJpcnWdK+4zHVuhPAxAj72KM36o4/qqrXt96OAr6Q5C+q6toZ1nkt8Diwp2+o0+6rqj7ZWXfafbbXdCN/uy9VfgD4tcmZWX6NtcB5ZKEFof2l+8kkNwC/keTYJN9sf2V/I8lL2rjXJvlimz6v/a7BV5Pck+TdQ9t7fGj8V5NcleQ7SS5Lkrbs1Fa7OcmFk9udSVXdCpzP4MuKJHlDkhtan3+QZHmSlcA7gX/bjpZePdW4Z7Gv85L8+zb97iR3JrktyRXT7HP31/QdST4+tIufTTKR5P9MHsHsPibJF9tr+GHgR9u2L9vtNU6S30xye5JvJ3lb77XX3scjCy0kK4BXVtVTSQ4AXl1Vu5L8LIO/aP/ZFOu8FPgZ4AXA3Ukuqqq/2m3M0cDLgP8H/DHwqiQTwO8Ar6mqezP4RvCovgX8cpv+OnB8VVWSfwW8r6rem+STDB0xJVm6+zjgvXu4r2HnAEdU1ZNJDqqqR6fY51k8/TV9x27bWMngNvQvAq5L8uLpmqiqc5L8YlUdNcXiNzE4Unw5cAhwU5KvtWXPeO0ZvGbayxgWWkg+V1VPtekDgQ1JVgEF7DfNOr9fVU8CTybZDixncCv1YTdW1VaAJLcyeJN8HLinqu5tYy4H1o3Y5/BfxyuAzyY5FNgfuHfqVUYeN9O+ht0GXJbkC8AXZlh/+DXd3ZVV9dfA5iT3MAjeZ+Ongcvbfh5K8ofAPwG+y9SvvWGxF/I0lBaSJ4amPwhcV1X/CHgD8Lxp1nlyaPoppv4DaJQxe+JoBvfKAvgY8PGq+kngF2boc9RxM+1r2M8x+BXDYxj8JT/dv+mJaeowCOHd53fx9PeFUfuczmy/9ponhoUWqgP54e3Q3zGG7d8N/EQ71w/wtlFWSvJTwH9k8EYNT+9z7dDQ7zE4NUZn3J7sa7K+D3B4VV0H/Erb9vOn2GfPW5Lsk+RFwE8weE3+FDiq1Q9ncJpq0l8lmeoI74+AtyXZN8ky4DXAjXvQh/YCprwWqt9gcBrqPwC/P9sbr6q/SPJvgC8neYLB7din8+oktwA/BmwH3j10JdR5wOeSPAJ8BTii1X8PuCrJGuBdM4zbk31N2hf470kOZHCa6sL2mcXu++z5MwZv6gcA76yqHyT5YwanyO5kcETzraHxFwO3JflWVf38UP3zwCuAP2FwdPK+qnowybM9raUFyLvOatFK8vyqerxdofMJYHNVXTDffUkLkaehtJj96/ah6x0MTuX8zjz3Iy1YHllIkro8spAkdRkWkqQuw0KS1GVYSJK6DAtJUtf/B/7g5CMkJv34AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDfComIDTpxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "6d028d53-68df-49fc-d836-e465fae7842d"
      },
      "source": [
        "sns.countplot(df_valid['label'].values)\n",
        "plt.xlabel(\"Testing Data Distribution\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Testing Data Distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP0tuBkhVWP3",
        "colab_type": "text"
      },
      "source": [
        "#### Choosing maximum sequence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q-mgyjxVT1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_lens = []\n",
        "for txt in df_train.sentence:\n",
        "  tokens = txt.split()\n",
        "  token_lens.append(len(tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFlyLji5VUka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ed95c1ff-780f-44c5-b340-24e9ae3f8c85"
      },
      "source": [
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 512]);\n",
        "plt.xlabel('Token lengths');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u3m3qTSVIzE",
        "colab_type": "text"
      },
      "source": [
        "### Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntFj0qERBiZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "e1ef918514b94bbd8828a48e43d387ca",
            "4145406ccce941ea920caa10bd0b34eb",
            "31524e875c8f4cc5aa4273fbb282f086",
            "c009161d6f484e5faffef66d578f0eb0",
            "3ff1b0ffc9f5403481b86df6b2c60125",
            "c0fe0817ada54269ab6a3e93214b6cde",
            "e28992ddfd974387a4777b97b18a1749",
            "87d2e814fc0c45ae90bb4da94e5b029d"
          ]
        },
        "outputId": "18ff1988-07b0-4a67-fb60-8d44c051eedb"
      },
      "source": [
        "OUTPUT_DIM = 1\n",
        "\n",
        "MAX_LEN = 100\n",
        "\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 8\n",
        "\n",
        "EPOCHS = 3\n",
        "\n",
        "TEACHER_MODEL_NAME = \"bert-base-uncased\"\n",
        "STUDENT_MODEL_NAME = \"distilbert-base-uncased\"\n",
        "\n",
        "TEACHER_MODEL_PATH = \"teacher_model.bin\"\n",
        "STUDENTSA_MODEL_PATH = \"studentsa_model.bin\"\n",
        "STUDENT_MODEL_PATH = \"student_model.bin\"\n",
        "\n",
        "TOKENIZER = transformers.BertTokenizer.from_pretrained(TEACHER_MODEL_NAME)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1ef918514b94bbd8828a48e43d387ca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1h5GxYDn4Ls",
        "colab_type": "text"
      },
      "source": [
        "### CoLA Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5cBnlbX76SO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CoLADataset:\n",
        "    def __init__(self, sentences, labels):\n",
        "        \n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "\n",
        "        self.tokenizer = TOKENIZER\n",
        "        self.max_len = MAX_LEN\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        sentence = self.sentences[item]\n",
        "        label = self.labels[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            truncation=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"ids\": encoding[\"input_ids\"].flatten(),\n",
        "            \"mask\": encoding[\"attention_mask\"].flatten(),\n",
        "            \"targets\": torch.tensor(label, dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9Bn4a0ayMM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = CoLADataset(\n",
        "    sentences=df_train.sentence.values,\n",
        "    labels=df_train.label.values\n",
        ")\n",
        "\n",
        "valid_dataset = CoLADataset(\n",
        "    sentences=df_valid.sentence.values,\n",
        "    labels=df_valid.label.values\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWsrzMz_n8FY",
        "colab_type": "text"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTFtEOuOykGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    TRAIN_BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "valid_data_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset,\n",
        "    VALID_BATCH_SIZE\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9Q2P-pWG1_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "93a54c85-6181-4590-970e-75c04d414537"
      },
      "source": [
        "sample = next(iter(train_data_loader))\n",
        "sample[\"ids\"].shape, sample[\"mask\"].shape, sample[\"targets\"].shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 100]), torch.Size([8, 100]), torch.Size([8]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QREE1MAPn-v0",
        "colab_type": "text"
      },
      "source": [
        "## BERT Model (Teacher)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7bWv8AB9h6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained(TEACHER_MODEL_NAME)\n",
        "        self.bert_drop = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(768, OUTPUT_DIM)\n",
        "    \n",
        "    def forward(self, ids, mask):\n",
        "        _, o2 = self.bert(ids, attention_mask=mask)\n",
        "        bo = self.bert_drop(o2)\n",
        "        output = self.out(bo)\n",
        "        return output"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43Vi_GvxzB_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bd509f2084fa4142b496243036ea7ff4",
            "ad969fdee59a4cd890e4db4ca91e6251",
            "d7dca0957b674c3b903492b2e23c9372",
            "b081a397aef747c0bd20dacf6b85962f",
            "ef5e9b9d33c14ff5b43895c824955bcf",
            "f32349e4205f4453801c00bb54516cd0",
            "15959302203f40b98a01dc87972c8e85",
            "d536fb716498440ba8b809a57fac1ad3",
            "0dc0f7a3f0214c55b74d26a3bf36741e",
            "98f2f6bb0c96442186442dfd84c80d60",
            "dc3abb818bb94be48b4493b063c4de8a",
            "3fc16b08566e49a59372f975f6cec026",
            "e689a5a85e354d3aa20a1600e19bdd9f",
            "e47ef712fba54a38a52afd8b9ad8f945",
            "6a16c0c5750446ad90b494a12ebb9091",
            "44455a3b72b047ddb590428b8c1fb7d1"
          ]
        },
        "outputId": "0b1da1ec-b027-44b9-ae12-570c533e2024"
      },
      "source": [
        "teacher_model = BERTModel()\n",
        "teacher_model.to(device)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd509f2084fa4142b496243036ea7ff4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dc0f7a3f0214c55b74d26a3bf36741e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (bert_drop): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxBbZ4veoBqw",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-oeyVX7zE4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create parameters we want to optimize\n",
        "# we generally dont use any decay for bias and weight layers\n",
        "\n",
        "param_optimizer = list(teacher_model.named_parameters())\n",
        "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "\n",
        "optimizer_parameters = [\n",
        "    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay) \n",
        "        ],\n",
        "        \"weight_decay\": 0.001,\n",
        "    },\n",
        "    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "        ],\n",
        "        \"weight_decay\": 0.0\n",
        "    }\n",
        "]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW_oeGXeFQKL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5deb0ee0-13ba-46d4-bd2d-8bb6fafdd2ef"
      },
      "source": [
        "num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
        "num_train_steps"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OOkyKXTFZEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(optimizer_parameters, lr=3e-5)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D1P0xa-oEFX",
        "colab_type": "text"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVh1cNH5FeV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_train_steps\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjrM4c5OoF_Q",
        "colab_type": "text"
      },
      "source": [
        "### Loss Criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdoq2_-HFrml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss().to(device)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3tJa9rKoHk7",
        "colab_type": "text"
      },
      "source": [
        "### Training Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys0Q2iD1-MvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_fn(data_loader, model, optimizer, criterion, device, scheduler):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in data_loader:\n",
        "        ids = batch['ids'].to(device)\n",
        "        mask = batch[\"mask\"].to(device)\n",
        "        targets = batch[\"targets\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(\n",
        "            ids=ids,\n",
        "            mask=mask\n",
        "        )\n",
        "\n",
        "        loss = criterion(outputs, targets.view(-1, 1))\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    return epoch_loss / len(data_loader)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtOoYuSboJmB",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEjTX3SZ_Guw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_fn(data_loader, model, criterion, device):\n",
        "    model.eval()\n",
        "\n",
        "    fin_outputs = []\n",
        "    fin_targets = []\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            ids = batch[\"ids\"].to(device)\n",
        "            mask = batch[\"mask\"].to(device)\n",
        "            targets = batch[\"targets\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                ids=ids,\n",
        "                mask=mask\n",
        "            )\n",
        "\n",
        "            loss = criterion(outputs, targets.view(-1, 1))\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            targets = targets.cpu().detach()\n",
        "            fin_targets.extend(targets.numpy().tolist())\n",
        "\n",
        "            outputs = torch.sigmoid(outputs).cpu().detach()\n",
        "            fin_outputs.extend(outputs.numpy().tolist())\n",
        "    outputs = np.array(fin_outputs) >= 0.5\n",
        "    accuracy = metrics.accuracy_score(fin_targets, outputs)\n",
        "    mat_cor = metrics.matthews_corrcoef(fin_targets, outputs)\n",
        "    return epoch_loss / len(data_loader), accuracy, mat_cor"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxpw7YJzqyoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43xKhkSyoL7N",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiJjDeRVB4Xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "dadedb0b-d177-4f7b-b22b-e0357018eff0"
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train_fn(train_data_loader, teacher_model, optimizer, criterion, device, scheduler)\n",
        "    val_loss, val_acc, val_mat_cor = eval_fn(valid_data_loader, teacher_model, criterion, device)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if val_loss < best_valid_loss:\n",
        "        best_valid_loss = val_loss\n",
        "        torch.save(teacher_model.state_dict(), TEACHER_MODEL_PATH)\n",
        "    \n",
        "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
        "    print(f\"\\t Train Loss: {train_loss:.3f}\")\n",
        "    print(f\"\\t Valid Loss: {val_loss:.3f} | Valid Acc: {val_acc * 100:.2f} | Matthews Cor: {val_mat_cor:.3f}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 55s\n",
            "\t Train Loss: 0.490\n",
            "\t Valid Loss: 0.362 | Valid Acc: 84.06 | Matthews Cor: 0.615\n",
            "Epoch: 02 | Epoch Time: 1m 54s\n",
            "\t Train Loss: 0.245\n",
            "\t Valid Loss: 0.427 | Valid Acc: 82.54 | Matthews Cor: 0.569\n",
            "Epoch: 03 | Epoch Time: 1m 55s\n",
            "\t Train Loss: 0.111\n",
            "\t Valid Loss: 0.494 | Valid Acc: 83.11 | Matthews Cor: 0.584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEABcJ99Z3h8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9014a65-ef2a-4730-be64-8a24e408c3dc"
      },
      "source": [
        "teacher_model.load_state_dict(torch.load(TEACHER_MODEL_PATH))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-7Nkskiha6j",
        "colab_type": "text"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OahX_ZaccT28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(sentence, model, device):\n",
        "    encoded = TOKENIZER.encode_plus(\n",
        "        sentence,\n",
        "        max_length=MAX_LEN,\n",
        "        add_special_tokens=True,\n",
        "        return_token_type_ids=False,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    input_ids = encoded['input_ids'].to(device)\n",
        "    attention_mask = encoded['attention_mask'].to(device)\n",
        "    output = model(input_ids, attention_mask)\n",
        "    prediction = torch.round(torch.sigmoid(output))\n",
        "    print(f'Sentence: {sentence}')\n",
        "    print(f'Grammatically Correct: {prediction.item()}')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ1uLLNVlq6c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2684e9d7-4456-403a-b7af-6d71e6946756"
      },
      "source": [
        "sentence = \"I like coding\"\n",
        "inference(sentence, teacher_model, device)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: I like coding\n",
            "Grammatically Correct: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX2V77wRlwwf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "52382fb2-2852-4ab8-8eb5-0341ba7b4c7d"
      },
      "source": [
        "sentence = \"I myself talking to\"\n",
        "inference(sentence, teacher_model, device)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: I myself talking to\n",
            "Grammatically Correct: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyb8LaSOmNI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3e1c6ae0-bf80-450f-c30d-498968487f63"
      },
      "source": [
        "sentence = \"I am talking to myself\"\n",
        "inference(sentence, teacher_model, device)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: I am talking to myself\n",
            "Grammatically Correct: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVMBv8IzbG3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vewRSr5EX0We",
        "colab_type": "text"
      },
      "source": [
        "## DistilBERT Model (Standalone)\n",
        "\n",
        "Without any teacher forcing from BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPpQyQIEX9ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DistilBERTModelSA(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = transformers.DistilBertModel.from_pretrained(STUDENT_MODEL_NAME)\n",
        "        self.bert_drop = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(768, OUTPUT_DIM)\n",
        "    \n",
        "    def forward(self, ids, mask):\n",
        "        output = self.bert(ids, attention_mask=mask)\n",
        "        hidden = output[0]\n",
        "        bo = self.bert_drop(hidden[:, 0])\n",
        "        output = self.out(bo)\n",
        "        return output"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-tjuTB-ZLUq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9003ac5c-8715-4b19-a17e-65ce1c65e9f7"
      },
      "source": [
        "student_model_sa = DistilBERTModelSA()\n",
        "student_model_sa.to(device)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBERTModelSA(\n",
              "  (bert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (bert_drop): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLQnxyU-ZWFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_optimizer = list(student_model_sa.named_parameters())\n",
        "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "\n",
        "optimizer_parameters = [\n",
        "    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay) \n",
        "        ],\n",
        "        \"weight_decay\": 0.001,\n",
        "    },\n",
        "    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "        ],\n",
        "        \"weight_decay\": 0.0\n",
        "    }\n",
        "]"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3epipcytZcDg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f0fede91-c0cf-40ff-919e-aa0c5871aaf6"
      },
      "source": [
        "num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
        "num_train_steps"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42jCUY1sZe4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(optimizer_parameters, lr=3e-5)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_kwNijFZsQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_train_steps\n",
        ")"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26FwS5d6Zssi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss().to(device)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejEkcnQBZvR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_fn(data_loader, model, optimizer, criterion, device, scheduler):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in data_loader:\n",
        "        ids = batch['ids'].to(device)\n",
        "        mask = batch[\"mask\"].to(device)\n",
        "        targets = batch[\"targets\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(\n",
        "            ids=ids,\n",
        "            mask=mask\n",
        "        )\n",
        "\n",
        "        loss = criterion(outputs, targets.view(-1, 1))\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    return epoch_loss / len(data_loader)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qi2S-y5ZzPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_fn(data_loader, model, criterion, device):\n",
        "    model.eval()\n",
        "\n",
        "    fin_outputs = []\n",
        "    fin_targets = []\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            ids = batch[\"ids\"].to(device)\n",
        "            mask = batch[\"mask\"].to(device)\n",
        "            targets = batch[\"targets\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                ids=ids,\n",
        "                mask=mask\n",
        "            )\n",
        "\n",
        "            loss = criterion(outputs, targets.view(-1, 1))\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            targets = targets.cpu().detach()\n",
        "            fin_targets.extend(targets.numpy().tolist())\n",
        "\n",
        "            outputs = torch.sigmoid(outputs).cpu().detach()\n",
        "            fin_outputs.extend(outputs.numpy().tolist())\n",
        "    outputs = np.array(fin_outputs) >= 0.5\n",
        "    accuracy = metrics.accuracy_score(fin_targets, outputs)\n",
        "    mat_cor = metrics.matthews_corrcoef(fin_targets, outputs)\n",
        "    return epoch_loss / len(data_loader), accuracy, mat_cor"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PK9essFZ4eQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF_K6t0JZ7C5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "eb7d01e0-ad98-4f7a-a16a-d7756846b3b9"
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train_fn(train_data_loader, student_model_sa, optimizer, criterion, device, scheduler)\n",
        "    val_loss, val_acc, val_mat_cor = eval_fn(valid_data_loader, student_model_sa, criterion, device)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if val_loss < best_valid_loss:\n",
        "        best_valid_loss = val_loss\n",
        "        torch.save(student_model_sa.state_dict(), STUDENTSA_MODEL_PATH)\n",
        "    \n",
        "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
        "    print(f\"\\t Train Loss: {train_loss:.3f}\")\n",
        "    print(f\"\\t Valid Loss: {val_loss:.3f} | Valid Acc: {val_acc * 100:.2f} | Matthews Cor: {val_mat_cor:.3f}\")"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 1s\n",
            "\t Train Loss: 0.528\n",
            "\t Valid Loss: 0.458 | Valid Acc: 77.99 | Matthews Cor: 0.450\n",
            "Epoch: 02 | Epoch Time: 1m 1s\n",
            "\t Train Loss: 0.292\n",
            "\t Valid Loss: 0.467 | Valid Acc: 80.65 | Matthews Cor: 0.523\n",
            "Epoch: 03 | Epoch Time: 1m 1s\n",
            "\t Train Loss: 0.132\n",
            "\t Valid Loss: 0.576 | Valid Acc: 82.54 | Matthews Cor: 0.570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMl8tKyiaGXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9ee1d078-6634-4224-9e04-6f6a306e72ab"
      },
      "source": [
        "student_model_sa.load_state_dict(torch.load(STUDENTSA_MODEL_PATH))"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l8F1xvaaL1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(sentence, model, device):\n",
        "    encoded = TOKENIZER.encode_plus(\n",
        "        sentence,\n",
        "        max_length=MAX_LEN,\n",
        "        add_special_tokens=True,\n",
        "        return_token_type_ids=False,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    input_ids = encoded['input_ids'].to(device)\n",
        "    attention_mask = encoded['attention_mask'].to(device)\n",
        "    output = model(input_ids, attention_mask)\n",
        "    prediction = torch.round(torch.sigmoid(output))\n",
        "    print(f'Sentence: {sentence}')\n",
        "    print(f'Grammatically Correct: {prediction.item()}')"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU2rkNjSaRU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a57a3e09-69be-4f6d-97e5-fed1aeb3e7f1"
      },
      "source": [
        "sentence = \"I like coding\"\n",
        "inference(sentence, student_model_sa, device)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: I like coding\n",
            "Grammatically Correct: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHG4bq7Ef7_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XRLzh75X-0P",
        "colab_type": "text"
      },
      "source": [
        "## DistilBERT Model (With Teacher Forcing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sdKUvvlYERu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DistilBERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = transformers.DistilBertModel.from_pretrained(STUDENT_MODEL_NAME)\n",
        "        self.bert_drop = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(768, OUTPUT_DIM)\n",
        "    \n",
        "    def forward(self, ids, mask):\n",
        "        output = self.bert(ids, attention_mask=mask)\n",
        "        hidden = output[0]\n",
        "        bo = self.bert_drop(hidden[:, 0])\n",
        "        output = self.out(bo)\n",
        "        return output"
      ],
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyoenrFzbiEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18cb09bc-fbbf-48d2-fe87-6ed6c2376df0"
      },
      "source": [
        "student_model = DistilBERTModel()\n",
        "student_model.to(device)"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBERTModel(\n",
              "  (bert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (bert_drop): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0HcKvjqbmVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_optimizer = list(student_model.named_parameters())\n",
        "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "\n",
        "optimizer_parameters = [\n",
        "    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay) \n",
        "        ],\n",
        "        \"weight_decay\": 0.001,\n",
        "    },\n",
        "    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "        ],\n",
        "        \"weight_decay\": 0.0\n",
        "    }\n",
        "]"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qV3ldzzbrYN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47cc9fc8-6cb2-43e2-e44a-efbd00b6a269"
      },
      "source": [
        "num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
        "num_train_steps"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxTTMQQWbuLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(optimizer_parameters, lr=3e-5)"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fOn42qebxec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_train_steps\n",
        ")"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zwnezljb0cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "MSE_loss = nn.MSELoss(reduction='mean')\n",
        "KLD_loss = nn.KLDivLoss(reduction=\"batchmean\")"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFUAAkhob5IQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_fn(data_loader, model, teacher_model, optimizer, criterion, device, scheduler, alpha_clf=1.0, alpha_teacher=1.0, temperature=2.0):\n",
        "    model.train()\n",
        "    epoch_clf_loss = 0\n",
        "    epoch_total_loss = 0\n",
        "\n",
        "    for batch in data_loader:\n",
        "        ids = batch['ids'].to(device)\n",
        "        mask = batch[\"mask\"].to(device)\n",
        "        targets = batch[\"targets\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        student_logits = model(\n",
        "            ids=ids,\n",
        "            mask=mask\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher_model(\n",
        "                ids=ids,\n",
        "                mask=mask\n",
        "            )\n",
        "        \n",
        "        mse_loss = MSE_loss(student_logits, teacher_logits)\n",
        "        kld_loss = KLD_loss(\n",
        "                    (student_logits / temperature),\n",
        "                    (teacher_logits / temperature),\n",
        "                ) \n",
        "        clf_loss = criterion(student_logits, targets.view(-1, 1))\n",
        "        teacher_loss = mse_loss + kld_loss\n",
        "        loss = alpha_clf * clf_loss + alpha_teacher * teacher_loss\n",
        "\n",
        "        epoch_clf_loss += clf_loss.item()\n",
        "        epoch_total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    return epoch_clf_loss / len(data_loader), epoch_total_loss / len(data_loader)"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-CJ79Iub9qG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_fn(data_loader, model, teacher_model, criterion, device, alpha_clf=1.0, alpha_teacher=1.0, temperature=2.0):\n",
        "    model.eval()\n",
        "\n",
        "    fin_outputs = []\n",
        "    fin_targets = []\n",
        "    epoch_clf_loss = 0\n",
        "    epoch_total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            ids = batch[\"ids\"].to(device)\n",
        "            mask = batch[\"mask\"].to(device)\n",
        "            targets = batch[\"targets\"].to(device)\n",
        "\n",
        "            student_logits = model(\n",
        "                ids=ids,\n",
        "                mask=mask\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher_model(\n",
        "                    ids=ids,\n",
        "                    mask=mask\n",
        "                )\n",
        "            \n",
        "            mse_loss = MSE_loss(student_logits, teacher_logits)\n",
        "            kld_loss = KLD_loss(\n",
        "                        (student_logits / temperature),\n",
        "                        (teacher_logits / temperature),\n",
        "                    ) \n",
        "\n",
        "            clf_loss = criterion(student_logits, targets.view(-1, 1))\n",
        "            teacher_loss = mse_loss + kld_loss\n",
        "            loss = alpha_clf * clf_loss + alpha_teacher * teacher_loss\n",
        "\n",
        "            epoch_clf_loss += clf_loss.item()\n",
        "            epoch_total_loss += loss.item()\n",
        "\n",
        "            targets = targets.cpu().detach()\n",
        "            fin_targets.extend(targets.numpy().tolist())\n",
        "\n",
        "            outputs = torch.sigmoid(student_logits).cpu().detach()\n",
        "            fin_outputs.extend(outputs.numpy().tolist())\n",
        "    outputs = np.array(fin_outputs) >= 0.5\n",
        "    accuracy = metrics.accuracy_score(fin_targets, outputs)\n",
        "    mat_cor = metrics.matthews_corrcoef(fin_targets, outputs)\n",
        "    return epoch_clf_loss / len(data_loader), epoch_total_loss / len(data_loader), accuracy, mat_cor"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oXPf5lZcBC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmiSO6btdGOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19f9c1c4-0f72-4868-e8c4-891fac369cb2"
      },
      "source": [
        "teacher_model.load_state_dict(torch.load(TEACHER_MODEL_PATH))"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kckOLKkpcPI_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "719617d7-2b1a-4fc3-eb36-fa4f94276935"
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_clf_loss, train_total_loss = train_fn(train_data_loader, student_model, teacher_model, optimizer, criterion, device, scheduler)\n",
        "    val_clf_loss, val_total_loss, val_acc, val_mat_cor = eval_fn(valid_data_loader, student_model, teacher_model, criterion, device)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if val_loss < best_valid_loss:\n",
        "        best_valid_loss = val_loss\n",
        "        torch.save(student_model.state_dict(), STUDENT_MODEL_PATH)\n",
        "    \n",
        "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
        "    print(f\"\\t Train CLF Loss: {train_clf_loss:.3f} | Train total Loss: {train_total_loss:.3f}\")\n",
        "    print(f\"\\t Valid CLF Loss: {val_clf_loss:.3f} | Valid total Loss: {val_total_loss:.3f}\")\n",
        "    print(f\"\\t Valid Acc: {val_acc * 100:.2f} | Matthews Cor: {val_mat_cor:.3f}\")"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 33s\n",
            "\t Train CLF Loss: 0.497 | Train total Loss: 1.807\n",
            "\t Valid CLF Loss: 0.432 | Valid total Loss: 0.521\n",
            "\t Valid Acc: 82.35 | Matthews Cor: 0.569\n",
            "Epoch: 02 | Epoch Time: 1m 33s\n",
            "\t Train CLF Loss: 0.328 | Train total Loss: 0.071\n",
            "\t Valid CLF Loss: 0.427 | Valid total Loss: 0.626\n",
            "\t Valid Acc: 82.92 | Matthews Cor: 0.579\n",
            "Epoch: 03 | Epoch Time: 1m 33s\n",
            "\t Train CLF Loss: 0.276 | Train total Loss: -0.295\n",
            "\t Valid CLF Loss: 0.419 | Valid total Loss: 0.436\n",
            "\t Valid Acc: 82.92 | Matthews Cor: 0.579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgBgLBT8cVvE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9be38a7b-dc12-4172-902a-cc7e2ca591f7"
      },
      "source": [
        "student_model.load_state_dict(torch.load(STUDENT_MODEL_PATH))"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opt4tZH6cai7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(sentence, model, device):\n",
        "    encoded = TOKENIZER.encode_plus(\n",
        "        sentence,\n",
        "        max_length=MAX_LEN,\n",
        "        add_special_tokens=True,\n",
        "        return_token_type_ids=False,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    input_ids = encoded['input_ids'].to(device)\n",
        "    attention_mask = encoded['attention_mask'].to(device)\n",
        "    output = model(input_ids, attention_mask)\n",
        "    prediction = torch.round(torch.sigmoid(output))\n",
        "    print(f'Sentence: {sentence}')\n",
        "    print(f'Grammatically Correct: {prediction.item()}')"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuZ6PB3cc43e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4fdc5c94-b1cd-4607-cc1b-076210b88054"
      },
      "source": [
        "sentence = \"I like coding\"\n",
        "inference(sentence, student_model, device)"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: I like coding\n",
            "Grammatically Correct: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgCg5akln97q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 226,
      "outputs": []
    }
  ]
}